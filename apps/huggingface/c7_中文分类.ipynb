{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05aa3c9-b77a-475d-b891-55dd7cfdf3d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db6b18a-32fd-4dc5-b490-496300c488fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 定义数据集\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, split):\n",
    "        # self.dataset = load_dataset('lansinuote/ChnSentiCorp', split=split)\n",
    "        self.dataset = load_from_disk('./data/ChnSentiCorp')['%s' % split]\n",
    "        print(self.dataset['text'][0])\n",
    "        print(self.dataset['label'][0])\n",
    "        # self.dataset = load_from_disk('./data/ChnSentiCorp')\n",
    "        # print(self.dataset)\n",
    "        # self.dataset = datasets.fetch_openml('./data/ChnSentiCorp', split=split)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        text = self.dataset['text'][i]\n",
    "        label = self.dataset['label'][i]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94f8de82-6e74-491c-b022-5d0e9e836d63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Dataset at 0x7f4590595070>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset = Dataset('train') #['train']\n",
    "\n",
    "# print(dataset['train'][0:10])\n",
    "# print(dataset['train'][1])\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1313fb25-3d2f-4ffe-94a9-fa132a05c983",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9741a49-f59b-4867-bcf3-62025a70c23e",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a539e0d1-57ba-4470-80b3-9afb0904861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token:  BertTokenizer(name_or_path='bert-base-chinese', vocab_size=21128, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "\n",
    "\n",
    "# 加载字典和分词工具\n",
    "token = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "print('token: ', token)\n",
    "\n",
    "\n",
    "# 加载预训练模型\n",
    "pretrained = BertModel.from_pretrained('bert-base-chinese').to(device)\n",
    "# print('pretrained ', pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc2674c-afd3-49dc-8efa-f0a7c43b214c",
   "metadata": {},
   "source": [
    "### 定义 collate_fn 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44d7da3f-5202-4d6f-9e89-e98b1e6048d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    # print(type(data))\n",
    "    # print('data数据: %s' % data)\n",
    "    # print('data长度: ', len(data))\n",
    "\n",
    "    \n",
    "    # 取每个评论的第一个字符作为数据, 第二作为标签\n",
    "    # 猫和老鼠的DVD,我在当当网已买过10余次了。除了做为礼物送给亲朋好有的孩子外，...\n",
    "    \n",
    "    sents =  [i[0] for i in data] # 猫 ...  16个\n",
    "    labels = [i[1] for i in data] # 和 ...   16个\n",
    "    \n",
    "    #print('sents: %s sents长度: %s' % (sents, len(sents)))\n",
    "    #print('labels: %s' % labels)    \n",
    "    \n",
    "    # 编码\n",
    "    data = token.batch_encode_plus(batch_text_or_text_pairs=sents,\n",
    "                                   truncation=True,\n",
    "                                   padding='max_length',\n",
    "                                   max_length=500,\n",
    "                                   return_tensors='pt',\n",
    "                                   return_length=True\n",
    "                                  )\n",
    "    \n",
    "    # dict_keys(['input_ids', 'token_type_ids', 'length', 'attention_mask'])\n",
    "    # print('编码后的date: ', data.keys()) \n",
    "    \n",
    "    #print('input_ids状态: ', data['input_ids'].shape) [16, 500]\n",
    "    #print('token_type_ids状态: ', data['token_type_ids'].shape) [16, 500]\n",
    "    #print('attention_mask状态: ', data['attention_mask'].shape) [16, 500]\n",
    "    \n",
    "    # 打印\n",
    "    # print(data['input_ids'])\n",
    "    \n",
    "    \n",
    "    # input_ids:编码之后的数字\n",
    "    # attention_mask:是补零的位置是0,其他位置是1\n",
    "    input_ids = data['input_ids']\n",
    "    attention_mask = data['attention_mask']\n",
    "    token_type_ids = data['token_type_ids']\n",
    "\n",
    "    return input_ids, attention_mask, token_type_ids, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5797c595-bc4f-4ce8-a768-dfdaea9b08b6",
   "metadata": {},
   "source": [
    "## 数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24347ac8-ffcf-40a4-ab4e-5bfcf71e4d23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 torch.Size([16, 500]) torch.Size([16, 500]) torch.Size([16, 500]) [1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0]\n",
      "\n",
      "\n",
      "1 torch.Size([16, 500]) torch.Size([16, 500]) torch.Size([16, 500]) [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]\n",
      "\n",
      "\n",
      "2 torch.Size([16, 500]) torch.Size([16, 500]) torch.Size([16, 500]) [0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1]\n",
      "\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 数据加载器\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                     batch_size=16,\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True)\n",
    "\n",
    "\n",
    "for i, values in enumerate(loader):\n",
    "    input_ids, attention_mask, token_type_ids, labels = values\n",
    "    \n",
    "    print('')\n",
    "    # print(i, values)\n",
    "    print(i, input_ids.shape, \n",
    "          attention_mask.shape, \n",
    "          token_type_ids.shape, \n",
    "          labels\n",
    "         )\n",
    "    print('')\n",
    "    if i >= 2:\n",
    "        break\n",
    "    \n",
    "\n",
    "print(len(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6fe6a5-fbb4-4622-8859-cc660c82eab3",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20b47b45-1ca2-41a4-91b0-7d35e689663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不训练,不需要计算梯度\n",
    "for param in pretrained.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "    \n",
    "#模型试算\n",
    "#out = pretrained(input_ids=input_ids,\n",
    "#           attention_mask=attention_mask,\n",
    "#           token_type_ids=token_type_ids)\n",
    "\n",
    "#out.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eea38d54-2c3d-47b8-b16b-afe02201f9b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义下游任务模型\n",
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        with torch.no_grad():\n",
    "            out = pretrained(input_ids=input_ids,\n",
    "                             attention_mask=attention_mask,\n",
    "                             token_type_ids=token_type_ids)\n",
    "            pass\n",
    "        out = self.fc(out.last_hidden_state[:, 0])\n",
    "        out = out.softmax(dim=1)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = Model()\n",
    "\n",
    "\n",
    "#model(input_ids=input_ids,\n",
    "#      attention_mask=attention_mask,\n",
    "#      token_type_ids=token_type_ids\n",
    "#     ).shape\n",
    "\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81844361-4629-4469-97ee-7f54628b12b7",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9312a384-e700-46d7-a5e9-48ccf14098b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mylady/.virtualenvs/dl-pytorch/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7648610472679138 0.375\n",
      "5 0.657814621925354 0.5625\n",
      "10 0.6514464020729065 0.625\n",
      "15 0.7000013589859009 0.5625\n",
      "20 0.6312711238861084 0.6875\n",
      "25 0.586837649345398 0.9375\n",
      "30 0.6226174235343933 0.6875\n",
      "35 0.5676578879356384 0.9375\n",
      "40 0.5505883693695068 0.8125\n",
      "45 0.5024958848953247 0.9375\n",
      "50 0.45495858788490295 1.0\n",
      "55 0.5161272287368774 0.875\n",
      "60 0.4778011441230774 1.0\n",
      "65 0.5250521898269653 0.8125\n",
      "70 0.528820812702179 0.75\n",
      "75 0.4680573046207428 0.9375\n",
      "80 0.50459885597229 0.875\n",
      "85 0.5281070470809937 0.8125\n",
      "90 0.5644564032554626 0.875\n",
      "95 0.47969406843185425 0.8125\n",
      "100 0.4452677071094513 0.875\n",
      "105 0.46879222989082336 0.875\n",
      "110 0.48305755853652954 0.8125\n",
      "115 0.5238274335861206 0.875\n",
      "120 0.4700734317302704 0.9375\n",
      "125 0.5667294859886169 0.6875\n",
      "130 0.48260486125946045 0.875\n",
      "135 0.50947505235672 0.75\n",
      "140 0.4635060131549835 0.875\n",
      "145 0.42668217420578003 0.9375\n",
      "150 0.49074429273605347 0.8125\n",
      "155 0.4279915690422058 0.9375\n",
      "160 0.42926204204559326 0.9375\n",
      "165 0.4293033182621002 0.9375\n",
      "170 0.4070316553115845 0.9375\n",
      "175 0.45076796412467957 0.9375\n",
      "180 0.47279083728790283 0.8125\n",
      "185 0.46365082263946533 0.875\n",
      "190 0.4317065179347992 0.875\n",
      "195 0.37183746695518494 1.0\n",
      "200 0.3717629611492157 0.9375\n",
      "205 0.4039221405982971 0.9375\n",
      "210 0.41525065898895264 1.0\n",
      "215 0.47678810358047485 0.8125\n",
      "220 0.41641518473625183 1.0\n",
      "225 0.5315610766410828 0.6875\n",
      "230 0.44236305356025696 0.875\n",
      "235 0.47032520174980164 0.8125\n",
      "240 0.4540707468986511 0.875\n",
      "245 0.5907487869262695 0.6875\n",
      "250 0.39219173789024353 0.9375\n",
      "255 0.40856748819351196 0.9375\n",
      "260 0.5181506276130676 0.75\n",
      "265 0.4171188771724701 0.875\n",
      "270 0.4896060526371002 0.875\n",
      "275 0.40672385692596436 0.875\n",
      "280 0.4857463240623474 0.8125\n",
      "285 0.47533389925956726 0.875\n",
      "290 0.430121511220932 0.875\n",
      "295 0.4816588759422302 0.8125\n",
      "300 0.5040463209152222 0.8125\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "\n",
    "# 训练\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "model.train()\n",
    "\n",
    "\n",
    "for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(loader):\n",
    "    \n",
    "    # print('input_ids.shape: %s, labels.shape: %s \\n' % (input_ids.shape, labels.shape))\n",
    "    # print('input_ids: %s, labels: %s' % (input_ids, labels))\n",
    "    # print(\"\")\n",
    "    \n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    token_type_ids = token_type_ids.to(device)\n",
    "    labels = torch.tensor(labels).to(device)\n",
    "        \n",
    "    out = model(input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids)\n",
    "    # print('')\n",
    "    # print('out状态: ', out, out.shape)\n",
    "    # print('labels状态: ', labels, labels)\n",
    "    \n",
    "    # 梯度下降\n",
    "    l = loss(out, labels)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "    if i % 5 == 0:\n",
    "        out = out.cpu()\n",
    "        labels = labels.cpu()\n",
    "            \n",
    "        out = out.argmax(dim=1)\n",
    "        accuracy = (out == labels).sum().item() / len(labels)\n",
    "        print(i, l.item(), accuracy)\n",
    "\n",
    "    if i == 300:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade015f3-7b69-4ba3-8273-f29605376e9c",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57c14c9d-afa8-4d2c-bf3c-f2ebbf400295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_res():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    loader_test = torch.utils.data.DataLoader(dataset=Dataset('validation'),\n",
    "                                              batch_size=32,\n",
    "                                              collate_fn=collate_fn,\n",
    "                                              shuffle=True,\n",
    "                                              drop_last=True)\n",
    "\n",
    "    for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(loader_test):\n",
    "        \n",
    "        if i > 100:\n",
    "            break\n",
    "            \n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        token_type_ids = token_type_ids.to(device)\n",
    "        labels = torch.tensor(labels).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids)\n",
    "            pass\n",
    "        \n",
    "        out = out.cpu()\n",
    "        labels = labels.cpu()\n",
    "        out = out.argmax(dim=1)\n",
    "        \n",
    "        # print('text: %s, 预测值: %s, 真实值: %s' % (input_ids, out, labels))\n",
    "        \n",
    "        correct += (out == labels).sum().item()\n",
    "        total += len(labels)\n",
    "        \n",
    "        print('当前批次, acc: %s' % (out.sum() / (out == labels).sum()))\n",
    "\n",
    "    print('acc: ', correct / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c426871d-1416-4d09-a172-b2eabfc6d1a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "這間酒店環境和服務態度亦算不錯,但房間空間太小~~不宣容納太大件行李~~且房間格調還可以~~ 中餐廳的廣東點心不太好吃~~要改善之~~~~但算價錢平宜~~可接受~~ 西餐廳格調都很好~~但吃的味道一般且令人等得太耐了~~要改善之~~\n",
      "1\n",
      "当前批次, acc: tensor(0.6429)\n",
      "当前批次, acc: tensor(0.5385)\n",
      "当前批次, acc: tensor(0.4615)\n",
      "当前批次, acc: tensor(0.4815)\n",
      "当前批次, acc: tensor(0.5862)\n",
      "当前批次, acc: tensor(0.4138)\n",
      "当前批次, acc: tensor(0.5517)\n",
      "当前批次, acc: tensor(0.3600)\n",
      "当前批次, acc: tensor(0.4667)\n",
      "当前批次, acc: tensor(0.5357)\n",
      "当前批次, acc: tensor(0.3913)\n",
      "当前批次, acc: tensor(0.5185)\n",
      "当前批次, acc: tensor(0.6207)\n",
      "当前批次, acc: tensor(0.4286)\n",
      "当前批次, acc: tensor(0.5667)\n",
      "当前批次, acc: tensor(0.4286)\n",
      "当前批次, acc: tensor(0.4400)\n",
      "当前批次, acc: tensor(0.4667)\n",
      "当前批次, acc: tensor(0.5517)\n",
      "当前批次, acc: tensor(0.3448)\n",
      "当前批次, acc: tensor(0.6429)\n",
      "当前批次, acc: tensor(0.6538)\n",
      "当前批次, acc: tensor(0.7200)\n",
      "当前批次, acc: tensor(0.6000)\n",
      "当前批次, acc: tensor(0.3333)\n",
      "当前批次, acc: tensor(0.4516)\n",
      "当前批次, acc: tensor(0.7692)\n",
      "当前批次, acc: tensor(0.6429)\n",
      "当前批次, acc: tensor(0.5517)\n",
      "当前批次, acc: tensor(0.5517)\n",
      "当前批次, acc: tensor(0.5556)\n",
      "当前批次, acc: tensor(0.6000)\n",
      "当前批次, acc: tensor(0.4828)\n",
      "当前批次, acc: tensor(0.6333)\n",
      "当前批次, acc: tensor(0.2963)\n",
      "当前批次, acc: tensor(0.4828)\n",
      "当前批次, acc: tensor(0.7917)\n",
      "acc:  0.8682432432432432\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 测试结果\n",
    "test_res()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05475a9-9ccf-4968-a401-9fea74273ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c21da-e8a3-4fa1-a92a-7f1d12253d05",
   "metadata": {},
   "source": [
    "## 计算后的模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52a4ae6a-faae-4943-aaef-f62231cd4ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存\n",
    "torch.save(model.state_dict(), \n",
    "           'chinese_class_mission_2023_4_10.pt') # 推荐的文件后缀名是pt或pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f88ea207-8690-4be0-be5c-36a8cbbfd407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 封装检测类\n",
    "\n",
    "def str_felling_detect(model, str_sents):\n",
    "    \n",
    "\n",
    "    out = token.encode_plus(str_sents,\n",
    "                            # 当句子长度大于max_length时,截断\n",
    "                            truncation=True,\n",
    "                            # 一律补pad到 max_length长度\n",
    "                            padding='max_length',\n",
    "                            add_special_tokens=True,\n",
    "                            max_length=500,\n",
    "\n",
    "                            #可取值tf,pt,np,默认为返回list\n",
    "                            return_tensors=None,\n",
    "                            #返回token_type_ids\n",
    "                            return_token_type_ids=True,\n",
    "                            #返回attention_mask\n",
    "                            return_attention_mask=True,\n",
    "                            #返回special_tokens_mask 特殊符号标识\n",
    "                            return_special_tokens_mask=True,\n",
    "\n",
    "                            #返回offset_mapping 标识每个词的起止位置,\n",
    "                            # 这个参数只能BertTokenizerFast使用\n",
    "                            #return_offsets_mapping=True,\n",
    "\n",
    "                            #返回length 标识长度\n",
    "                            return_length=True\n",
    "                           )\n",
    "    \n",
    "    input_ids = torch.tensor([out['input_ids']]).to(device)\n",
    "    attention_mask = torch.tensor([out['attention_mask']]).to(device)\n",
    "    token_type_ids = torch.tensor([out['token_type_ids']]).to(device)\n",
    "\n",
    "    out_test = model(input_ids=input_ids,\n",
    "                     attention_mask=attention_mask,                 \n",
    "                     token_type_ids=token_type_ids\n",
    "                    )\n",
    "    print(out_test)\n",
    "    \n",
    "    # print(out_test.argmax(dim=1).cpu())  # tensor([1])\n",
    "    out_res = out_test.argmax(dim=1).cpu().item()\n",
    "    # print(out_res, type(out_res))  # <class 'int'>\n",
    "    \n",
    "    if out_res == 1:\n",
    "        print('1 正面情感输出')\n",
    "    elif out_res == 0:\n",
    "        print('0 负面情感输出')\n",
    "    else:\n",
    "        print('中性句子')\n",
    "\n",
    "    return out_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ca2406a-26e0-4df5-bbe6-5b5224cec97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0763, 0.9237]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "1 正面情感输出\n",
      "\n",
      "tensor([[0.9981, 0.0019]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "0 负面情感输出\n",
      "\n",
      "tensor([[0.9577, 0.0423]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "0 负面情感输出\n",
      "\n",
      "tensor([[0.8644, 0.1356]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "0 负面情感输出\n",
      "\n",
      "tensor([[0.0068, 0.9932]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "1 正面情感输出\n",
      "\n"
     ]
    }
   ],
   "source": [
    "str_1 = '选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁' \\\n",
    "       '泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般'\n",
    "\n",
    "str_2 = \"\"\"1.接电源没有几分钟,电源适配器热的不行. 2.摄像头用不起来. 3.机盖的钢琴漆，手不能摸，一摸一个印. 4.硬盘分区不好办.\"\"\"\n",
    "\n",
    "str_3 = '房间太小。其他的都一般。。。。。。。。。'\n",
    "\n",
    "str_4 = \"呵呵，虽然表皮看上去不错很精致，但是我还是能看得出来是盗的。但是里面的内容真的不错，我妈爱看，我自己也学着找一些穴位。\"\n",
    "\n",
    "str_5 =\"地理位置佳，在市中心。酒店服务好、早餐品种丰富。我住的商务数码房电脑宽带速度满意,房间还算干净，离湖南路小吃街近\"\n",
    "\n",
    "\n",
    "for str_sents in [str_1, str_2, str_3, str_4, str_5]:\n",
    "    str_felling_detect(model, str_sents)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732fbd2c-2f31-477c-bcc7-13f3406199be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
