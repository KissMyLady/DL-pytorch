{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d05aa3c9-b77a-475d-b891-55dd7cfdf3d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db6b18a-32fd-4dc5-b490-496300c488fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 定义数据集\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, split):\n",
    "        # self.dataset = load_dataset('lansinuote/ChnSentiCorp', split=split)\n",
    "        self.dataset = load_from_disk('./data/ChnSentiCorp')['%s' % split]\n",
    "        print(self.dataset['text'][0])\n",
    "        print(self.dataset['label'][0])\n",
    "        # self.dataset = load_from_disk('./data/ChnSentiCorp')\n",
    "        # print(self.dataset)\n",
    "        # self.dataset = datasets.fetch_openml('./data/ChnSentiCorp', split=split)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        text = self.dataset['text'][i]\n",
    "        label = self.dataset['label'][i]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94f8de82-6e74-491c-b022-5d0e9e836d63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Dataset at 0x7f816c41a520>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset = Dataset('train') #['train']\n",
    "\n",
    "# print(dataset['train'][0:10])\n",
    "# print(dataset['train'][1])\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1313fb25-3d2f-4ffe-94a9-fa132a05c983",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般',\n",
       " 1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9741a49-f59b-4867-bcf3-62025a70c23e",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a539e0d1-57ba-4470-80b3-9afb0904861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token:  BertTokenizer(name_or_path='bert-base-chinese', vocab_size=21128, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "\n",
    "\n",
    "# 加载字典和分词工具\n",
    "token = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "print('token: ', token)\n",
    "\n",
    "\n",
    "# 加载预训练模型\n",
    "pretrained = BertModel.from_pretrained('bert-base-chinese').to(device)\n",
    "# print('pretrained ', pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc2674c-afd3-49dc-8efa-f0a7c43b214c",
   "metadata": {},
   "source": [
    "### 定义 collate_fn 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44d7da3f-5202-4d6f-9e89-e98b1e6048d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    # print(type(data))\n",
    "    # print('data数据: %s' % data)\n",
    "    # print('data长度: ', len(data))\n",
    "\n",
    "    \n",
    "    # 取每个评论的第一个字符作为数据, 第二作为标签\n",
    "    # 猫和老鼠的DVD,我在当当网已买过10余次了。除了做为礼物送给亲朋好有的孩子外，...\n",
    "    \n",
    "    sents =  [i[0] for i in data] # 猫 ...  16个\n",
    "    labels = [i[1] for i in data] # 和 ...   16个\n",
    "    \n",
    "    #print('sents: %s sents长度: %s' % (sents, len(sents)))\n",
    "    #print('labels: %s' % labels)    \n",
    "    \n",
    "    # 编码\n",
    "    data = token.batch_encode_plus(batch_text_or_text_pairs=sents,\n",
    "                                   truncation=True,\n",
    "                                   padding='max_length',\n",
    "                                   max_length=500,\n",
    "                                   return_tensors='pt',\n",
    "                                   return_length=True\n",
    "                                  )\n",
    "    \n",
    "    # dict_keys(['input_ids', 'token_type_ids', 'length', 'attention_mask'])\n",
    "    # print('编码后的date: ', data.keys()) \n",
    "    \n",
    "    #print('input_ids状态: ', data['input_ids'].shape) [16, 500]\n",
    "    #print('token_type_ids状态: ', data['token_type_ids'].shape) [16, 500]\n",
    "    #print('attention_mask状态: ', data['attention_mask'].shape) [16, 500]\n",
    "    \n",
    "    # 打印\n",
    "    # print(data['input_ids'])\n",
    "    \n",
    "    \n",
    "    # input_ids:编码之后的数字\n",
    "    # attention_mask:是补零的位置是0,其他位置是1\n",
    "    input_ids = data['input_ids']\n",
    "    attention_mask = data['attention_mask']\n",
    "    token_type_ids = data['token_type_ids']\n",
    "\n",
    "    return input_ids, attention_mask, token_type_ids, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5797c595-bc4f-4ce8-a768-dfdaea9b08b6",
   "metadata": {},
   "source": [
    "## 数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24347ac8-ffcf-40a4-ab4e-5bfcf71e4d23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 torch.Size([16, 500]) torch.Size([16, 500]) torch.Size([16, 500]) [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0]\n",
      "\n",
      "\n",
      "1 torch.Size([16, 500]) torch.Size([16, 500]) torch.Size([16, 500]) [0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0]\n",
      "\n",
      "\n",
      "2 torch.Size([16, 500]) torch.Size([16, 500]) torch.Size([16, 500]) [1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n",
      "\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 数据加载器\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                     batch_size=16,\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True)\n",
    "\n",
    "\n",
    "for i, values in enumerate(loader):\n",
    "    input_ids, attention_mask, token_type_ids, labels = values\n",
    "    \n",
    "    print('')\n",
    "    # print(i, values)\n",
    "    print(i, input_ids.shape, \n",
    "          attention_mask.shape, \n",
    "          token_type_ids.shape, \n",
    "          labels\n",
    "         )\n",
    "    print('')\n",
    "    if i >= 2:\n",
    "        break\n",
    "    \n",
    "\n",
    "print(len(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6fe6a5-fbb4-4622-8859-cc660c82eab3",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20b47b45-1ca2-41a4-91b0-7d35e689663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不训练,不需要计算梯度\n",
    "for param in pretrained.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "    \n",
    "#模型试算\n",
    "#out = pretrained(input_ids=input_ids,\n",
    "#           attention_mask=attention_mask,\n",
    "#           token_type_ids=token_type_ids)\n",
    "\n",
    "#out.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eea38d54-2c3d-47b8-b16b-afe02201f9b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义下游任务模型\n",
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        with torch.no_grad():\n",
    "            out = pretrained(input_ids=input_ids,\n",
    "                             attention_mask=attention_mask,\n",
    "                             token_type_ids=token_type_ids)\n",
    "            pass\n",
    "        out = self.fc(out.last_hidden_state[:, 0])\n",
    "        out = out.softmax(dim=1)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = Model()\n",
    "\n",
    "\n",
    "#model(input_ids=input_ids,\n",
    "#      attention_mask=attention_mask,\n",
    "#      token_type_ids=token_type_ids\n",
    "#     ).shape\n",
    "\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81844361-4629-4469-97ee-7f54628b12b7",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9312a384-e700-46d7-a5e9-48ccf14098b5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6958725452423096 0.625\n",
      "5 0.7487972378730774 0.4375\n",
      "10 0.6864623427391052 0.5625\n",
      "15 0.7131083607673645 0.4375\n",
      "20 0.5900887846946716 0.75\n",
      "25 0.5897844433784485 0.875\n",
      "30 0.6619393229484558 0.5625\n",
      "35 0.6275553107261658 0.625\n",
      "40 0.564215362071991 0.875\n",
      "45 0.5329274535179138 0.9375\n",
      "50 0.5611305832862854 0.875\n",
      "55 0.5218709111213684 0.9375\n",
      "60 0.5288110971450806 0.9375\n",
      "65 0.5353909134864807 0.875\n",
      "70 0.5484877228736877 0.8125\n",
      "75 0.5157537460327148 0.875\n",
      "80 0.4717966914176941 0.9375\n",
      "85 0.5041393041610718 0.8125\n",
      "90 0.4816528558731079 0.9375\n",
      "95 0.47506433725357056 0.875\n",
      "100 0.47736144065856934 0.9375\n",
      "105 0.42665037512779236 1.0\n",
      "110 0.49181699752807617 0.8125\n",
      "115 0.46781566739082336 0.875\n",
      "120 0.4107031226158142 0.9375\n",
      "125 0.44184234738349915 0.9375\n",
      "130 0.4267587661743164 0.875\n",
      "135 0.4708537757396698 0.875\n",
      "140 0.45660653710365295 0.875\n",
      "145 0.5373218059539795 0.8125\n",
      "150 0.44355103373527527 0.9375\n",
      "155 0.4072643220424652 0.9375\n",
      "160 0.4500364661216736 0.9375\n",
      "165 0.5201813578605652 0.875\n",
      "170 0.4712945818901062 0.9375\n",
      "175 0.4697948396205902 0.875\n",
      "180 0.5013389587402344 0.8125\n",
      "185 0.4916529655456543 0.875\n",
      "190 0.5046185255050659 0.875\n",
      "195 0.531291127204895 0.8125\n",
      "200 0.45585182309150696 0.875\n",
      "205 0.46756041049957275 0.875\n",
      "210 0.47319307923316956 0.875\n",
      "215 0.47653526067733765 0.8125\n",
      "220 0.5193843841552734 0.75\n",
      "225 0.49201643466949463 0.875\n",
      "230 0.4881874918937683 0.8125\n",
      "235 0.5109002590179443 0.75\n",
      "240 0.42826923727989197 0.9375\n",
      "245 0.4524562954902649 0.875\n",
      "250 0.46511805057525635 0.875\n",
      "255 0.41141775250434875 0.9375\n",
      "260 0.41442587971687317 0.9375\n",
      "265 0.5810630321502686 0.75\n",
      "270 0.48515182733535767 0.8125\n",
      "275 0.4892719089984894 0.8125\n",
      "280 0.4236420691013336 0.9375\n",
      "285 0.5072540044784546 0.75\n",
      "290 0.4537310302257538 0.875\n",
      "295 0.5282148122787476 0.6875\n",
      "300 0.6726234555244446 0.5625\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "\n",
    "# 训练\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "model.train()\n",
    "\n",
    "\n",
    "for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(loader):\n",
    "    \n",
    "    # print('input_ids.shape: %s, labels.shape: %s \\n' % (input_ids.shape, labels.shape))\n",
    "    # print('input_ids: %s, labels: %s' % (input_ids, labels))\n",
    "    # print(\"\")\n",
    "    \n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    token_type_ids = token_type_ids.to(device)\n",
    "    labels = torch.tensor(labels).to(device)\n",
    "        \n",
    "    out = model(input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids)\n",
    "    # print('')\n",
    "    # print('out状态: ', out, out.shape)\n",
    "    # print('labels状态: ', labels, labels)\n",
    "    \n",
    "    # 梯度下降\n",
    "    l = loss(out, labels)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "    if i % 5 == 0:\n",
    "        out = out.cpu()\n",
    "        labels = labels.cpu()\n",
    "            \n",
    "        out = out.argmax(dim=1)\n",
    "        accuracy = (out == labels).sum().item() / len(labels)\n",
    "        print(i, l.item(), accuracy)\n",
    "\n",
    "    if i == 300:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade015f3-7b69-4ba3-8273-f29605376e9c",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57c14c9d-afa8-4d2c-bf3c-f2ebbf400295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_res():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    loader_test = torch.utils.data.DataLoader(dataset=Dataset('validation'),\n",
    "                                              batch_size=32,\n",
    "                                              collate_fn=collate_fn,\n",
    "                                              shuffle=True,\n",
    "                                              drop_last=True)\n",
    "\n",
    "    for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(loader_test):\n",
    "        \n",
    "        if i > 100:\n",
    "            break\n",
    "            \n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        token_type_ids = token_type_ids.to(device)\n",
    "        labels = torch.tensor(labels).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids)\n",
    "            pass\n",
    "        \n",
    "        out = out.cpu()\n",
    "        labels = labels.cpu()\n",
    "        out = out.argmax(dim=1)\n",
    "        \n",
    "        # print('text: %s, 预测值: %s, 真实值: %s' % (input_ids, out, labels))\n",
    "        \n",
    "        correct += (out == labels).sum().item()\n",
    "        total += len(labels)\n",
    "        \n",
    "        print('当前批次, acc: %s' % (out.sum() / (out == labels).sum()))\n",
    "\n",
    "    print('acc: ', correct / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c426871d-1416-4d09-a172-b2eabfc6d1a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "這間酒店環境和服務態度亦算不錯,但房間空間太小~~不宣容納太大件行李~~且房間格調還可以~~ 中餐廳的廣東點心不太好吃~~要改善之~~~~但算價錢平宜~~可接受~~ 西餐廳格調都很好~~但吃的味道一般且令人等得太耐了~~要改善之~~\n",
      "1\n",
      "当前批次, acc: tensor(0.8636)\n",
      "当前批次, acc: tensor(1.3125)\n",
      "当前批次, acc: tensor(0.6400)\n",
      "当前批次, acc: tensor(0.7917)\n",
      "当前批次, acc: tensor(0.8000)\n",
      "当前批次, acc: tensor(0.9130)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 测试结果\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtest_res\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 28\u001b[0m, in \u001b[0;36mtest_res\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m     24\u001b[0m                 attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m     25\u001b[0m                 token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     30\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# 测试结果\n",
    "test_res()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d05475a9-9ccf-4968-a401-9fea74273ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Dataset at 0x7f443c06a790>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40e40730-594c-4fec-b236-8ee1a189b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "str_v1 = '这句话的意思是，”因为我在思考，所以我存在”。笛卡尔把这句话作为他哲学思考的起点，他试图通过怀疑一切，最终找到一个不容置疑的真理。'\n",
    "\n",
    "\n",
    "out = token.encode_plus(str_v1,\n",
    "                        # 当句子长度大于max_length时,截断\n",
    "                        truncation=True,\n",
    "                        # 一律补pad到 max_length长度\n",
    "                        padding='max_length',\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=500,\n",
    "\n",
    "                        #可取值tf,pt,np,默认为返回list\n",
    "                        return_tensors=None,\n",
    "                        #返回token_type_ids\n",
    "                        return_token_type_ids=True,\n",
    "                        #返回attention_mask\n",
    "                        return_attention_mask=True,\n",
    "                        #返回special_tokens_mask 特殊符号标识\n",
    "                        return_special_tokens_mask=True,\n",
    "\n",
    "                        #返回offset_mapping 标识每个词的起止位置,\n",
    "                        # 这个参数只能BertTokenizerFast使用\n",
    "                        #return_offsets_mapping=True,\n",
    "\n",
    "                        #返回length 标识长度\n",
    "                        return_length=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "4ccd13cb-2396-4afa-a69a-7f65552588d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c63c33f-189b-4417-8d21-b6c30f21e22e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_ids = torch.tensor([out['input_ids']]).to(device)\n",
    "attention_mask = torch.tensor([out['attention_mask']]).to(device)\n",
    "token_type_ids = torch.tensor([out['token_type_ids']]).to(device)\n",
    "\n",
    "\n",
    "out_test = model(input_ids=input_ids,\n",
    "                 attention_mask=attention_mask,                 \n",
    "                 token_type_ids=token_type_ids\n",
    "                )\n",
    "\n",
    "\n",
    "out_res = out_test.argmax(dim=1).cpu()\n",
    "\n",
    "\n",
    "print(out_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca2406a-26e0-4df5-bbe6-5b5224cec97e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
