{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f39e611-dad8-4ab7-85f3-99e8e9661709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "# from d2l import torch as d2l\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dda3bd7-bf21-498e-879c-22b9a66a2faa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No compiled kernel found.\n",
      "Compiling kernels : /home/mylady/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4/e02ba894cf18f3fd9b2526c795f983683c4ec732/quantization_kernels_parallel.c\n",
      "Compiling gcc -O3 -fPIC -pthread -fopenmp -std=c99 /home/mylady/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4/e02ba894cf18f3fd9b2526c795f983683c4ec732/quantization_kernels_parallel.c -shared -o /home/mylady/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4/e02ba894cf18f3fd9b2526c795f983683c4ec732/quantization_kernels_parallel.so\n",
      "Load kernel : /home/mylady/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4/e02ba894cf18f3fd9b2526c795f983683c4ec732/quantization_kernels_parallel.so\n",
      "Setting CPU quantization kernel threads to 6\n",
      "Using quantization cache\n",
      "Applying quantization to glm layers\n",
      "加载完毕..\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", \n",
    "                                          trust_remote_code=True)\n",
    "\n",
    "\n",
    "chat_model = AutoModel.from_pretrained(\"THUDM/chatglm-6b-int4\", \n",
    "                                       trust_remote_code=True).half().cuda()\n",
    "\n",
    "print('加载完毕..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "557ddb5b-a953-4a59-b96a-e85e87cfa16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = chat_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2975a3f-da8b-4ff8-885d-00d373b2853a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The dtype of attention mask (torch.int64) is not bool\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"你好\", history=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a7192bf-0e3d-4882-b8ed-5b307e73cdc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好👋！我是人工智能助手 ChatGLM-6B，很高兴见到你，欢迎问我任何问题。'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e30210dc-3e6f-4593-9cd1-3ba47076f088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response, history = model.chat(tokenizer, \"晚上睡不着应该怎么办\", history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4441f747-fda5-4fa6-b835-50380eb62ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'以下时是一些有用的技巧，可以帮助在晚上入睡：\\n\\n1. 保持安静：尽可能减少噪音和刺激，例如手机和电视。\\n\\n2. 放松身体：尝试进行深呼吸或渐进性肌肉松弛来放松身体。\\n\\n3. 避免使用电子设备：手机和电脑的蓝光可能会干扰睡眠。建议在睡前 1-2 小时停止使用这些设备。\\n\\n4. 创造一个舒适的睡眠环境：使用舒适的床垫和枕头，保持房间的温度和湿度适宜。\\n\\n5. 避免饮食和饮料的刺激：避免饮用咖啡、茶和可乐等刺激性饮料，以及吃辛辣或油腻的食物。\\n\\n6. 睡前放松：在睡前 1-2 小时，进行一些放松的活动，例如阅读或洗澡，帮助放松身心。\\n\\n如果以上方法仍然无法入睡，建议咨询医生或睡眠专家，获取更专业的建议和帮助。'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d80ae5-87e0-4a86-9d74-7f06a89dcf34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
