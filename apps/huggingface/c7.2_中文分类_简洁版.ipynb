{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d05aa3c9-b77a-475d-b891-55dd7cfdf3d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8db6b18a-32fd-4dc5-b490-496300c488fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 定义数据集\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, split):\n",
    "        # self.dataset = load_dataset('lansinuote/ChnSentiCorp', split=split)\n",
    "        self.dataset = load_from_disk('./data/ChnSentiCorp')['%s' % split]\n",
    "        print(self.dataset['text'][0])\n",
    "        print(self.dataset['label'][0])\n",
    "        # self.dataset = load_from_disk('./data/ChnSentiCorp')\n",
    "        # print(self.dataset)\n",
    "        # self.dataset = datasets.fetch_openml('./data/ChnSentiCorp', split=split)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        text = self.dataset['text'][i]\n",
    "        label = self.dataset['label'][i]\n",
    "        return text, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94f8de82-6e74-491c-b022-5d0e9e836d63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般\n",
      "1\n",
      "9600\n",
      "i: 0, label: 1 选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般\n",
      "i: 1, label: 1 15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很美观，做工也相当不错\n",
      "i: 2, label: 0 房间太小。其他的都一般。。。。。。。。。\n",
      "i: 3, label: 0 1.接电源没有几分钟,电源适配器热的不行. 2.摄像头用不起来. 3.机盖的钢琴漆，手不能摸，一摸一个印. 4.硬盘分区不好办.\n",
      "i: 4, label: 1 今天才知道这书还有第6卷,真有点郁闷:为什么同一套书有两种版本呢?当当网是不是该跟出版社商量商量,单独出个第6卷,让我们的孩子不会有所遗憾。\n",
      "i: 5, label: 0 机器背面似乎被撕了张什么标签，残胶还在。但是又看不出是什么标签不见了，该有的都在，怪\n",
      "i: 6, label: 0 呵呵，虽然表皮看上去不错很精致，但是我还是能看得出来是盗的。但是里面的内容真的不错，我妈爱看，我自己也学着找一些穴位。\n",
      "i: 7, label: 0 这本书实在是太烂了,以前听浙大的老师说这本书怎么怎么不对,哪些地方都是误导的还不相信,终于买了一本看一下,发现真是~~~无语,这种书都写得出来\n",
      "i: 8, label: 1 地理位置佳，在市中心。酒店服务好、早餐品种丰富。我住的商务数码房电脑宽带速度满意,房间还算干净，离湖南路小吃街近。\n",
      "i: 9, label: 1 5.1期间在这住的，位置还可以，在市委市政府附近，要去商业区和步行街得打车，屋里有蚊子，虽然空间挺大，晚上熄灯后把窗帘拉上简直是伸手不见五指，很适合睡觉，但是会被该死的蚊子吵醒！打死了两只，第二天早上还是发现又没打死的，卫生间挺大，但是设备很老旧。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 打印数据\n",
    "dataset = Dataset('train') #['train']\n",
    "\n",
    "print(len(dataset))\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('i: %s, label: %s %s' % (i, dataset[i][1],  dataset[i][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9741a49-f59b-4867-bcf3-62025a70c23e",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a539e0d1-57ba-4470-80b3-9afb0904861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token:  BertTokenizer(name_or_path='bert-base-chinese', vocab_size=21128, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "\n",
    "\n",
    "# 加载字典和分词工具\n",
    "token = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "print('token: ', token)\n",
    "\n",
    "\n",
    "# 加载预训练模型\n",
    "pretrained = BertModel.from_pretrained('bert-base-chinese').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc2674c-afd3-49dc-8efa-f0a7c43b214c",
   "metadata": {},
   "source": [
    "### 定义 collate_fn 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44d7da3f-5202-4d6f-9e89-e98b1e6048d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    sents =  [i[0] for i in data] # 猫 ...  16个  shape: [16, 500]\n",
    "    labels = [i[1] for i in data] # 和 ...   16个\n",
    "\n",
    "    # 编码\n",
    "    data = token.batch_encode_plus(batch_text_or_text_pairs=sents,\n",
    "                                   truncation=True,\n",
    "                                   padding='max_length',\n",
    "                                   max_length=500,\n",
    "                                   return_tensors='pt',\n",
    "                                   return_length=True\n",
    "                                  )\n",
    "\n",
    "    input_ids = data['input_ids']\n",
    "    attention_mask = data['attention_mask']\n",
    "    token_type_ids = data['token_type_ids']\n",
    "    \n",
    "    return input_ids, attention_mask, token_type_ids, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5797c595-bc4f-4ce8-a768-dfdaea9b08b6",
   "metadata": {},
   "source": [
    "## 数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24347ac8-ffcf-40a4-ab4e-5bfcf71e4d23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([16, 500]) torch.Size([16, 500]) torch.Size([16, 500]) [0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1]\n",
      "1 torch.Size([16, 500]) torch.Size([16, 500]) torch.Size([16, 500]) [0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0]\n",
      "2 torch.Size([16, 500]) torch.Size([16, 500]) torch.Size([16, 500]) [0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0]\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 数据加载器\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                     batch_size=16,\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True)\n",
    "\n",
    "\n",
    "for i, values in enumerate(loader):\n",
    "    input_ids, attention_mask, token_type_ids, labels = values\n",
    "    # print(i, values)\n",
    "    print(i, input_ids.shape, \n",
    "          attention_mask.shape, \n",
    "          token_type_ids.shape, \n",
    "          labels\n",
    "         )\n",
    "    if i >= 2:\n",
    "        break\n",
    "    \n",
    "\n",
    "print(len(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6fe6a5-fbb4-4622-8859-cc660c82eab3",
   "metadata": {},
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eea38d54-2c3d-47b8-b16b-afe02201f9b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义下游任务模型\n",
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        with torch.no_grad():\n",
    "            out = pretrained(input_ids=input_ids,\n",
    "                             attention_mask=attention_mask,\n",
    "                             token_type_ids=token_type_ids)\n",
    "            pass\n",
    "        out = self.fc(out.last_hidden_state[:, 0])\n",
    "        out = out.softmax(dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c21da-e8a3-4fa1-a92a-7f1d12253d05",
   "metadata": {},
   "source": [
    "### 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a98b2b-c8f2-4ab9-a9e0-e9716ec84c55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存\n",
    "\n",
    "\n",
    "model_save_path = 'chinese_class_mission_2023_4_10.pt'\n",
    "# torch.save(model.state_dict(),  model_save_path)  # 推荐的文件后缀名是pt或pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c4bed3-a1f4-4565-bdf7-ba2100919957",
   "metadata": {},
   "source": [
    "### 加载计算好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aced74cc-9e9d-4f62-ac1a-0b6a12191762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载保存的模型\n",
    "\n",
    "model = Model()\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('chinese_class_mission_2023_4_10.pt'))\n",
    "\n",
    "\n",
    "# 转移到 GPU 上计算\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f88ea207-8690-4be0-be5c-36a8cbbfd407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 封装检测类\n",
    "\n",
    "def str_felling_detect(model, str_sents):\n",
    "    \n",
    "\n",
    "    out = token.encode_plus(str_sents,\n",
    "                            truncation=True,# 当句子长度大于max_length时,截断\n",
    "                            padding='max_length', # 一律补pad到 max_length长度\n",
    "                            add_special_tokens=True,\n",
    "                            max_length=500,\n",
    "                            return_tensors=None,\n",
    "                            return_token_type_ids=True,\n",
    "                            return_attention_mask=True,\n",
    "                            return_special_tokens_mask=True,\n",
    "                            return_length=True\n",
    "                           )\n",
    "    \n",
    "    input_ids = torch.tensor([out['input_ids']]).to(device)\n",
    "    attention_mask = torch.tensor([out['attention_mask']]).to(device)\n",
    "    token_type_ids = torch.tensor([out['token_type_ids']]).to(device)\n",
    "\n",
    "    out_test = model(input_ids=input_ids,\n",
    "                     attention_mask=attention_mask,                 \n",
    "                     token_type_ids=token_type_ids\n",
    "                    )\n",
    "    \n",
    "    print(out_test)\n",
    "    out_res = out_test.argmax(dim=1).cpu().item()  # <class 'int'>\n",
    "\n",
    "    if out_res == 1:\n",
    "        print('1 正面情感输出')\n",
    "    elif out_res == 0:\n",
    "        print('0 负面情感输出')\n",
    "    else:\n",
    "        print('中性句子')\n",
    "\n",
    "    return out_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78fc88aa-eec5-4e42-b020-a2e195dfc4e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9791, 0.0209]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "0 负面情感输出\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "str_1 = '一直抄作业虽然短期来说能节省时间成本，但总归是要期末考试的'\n",
    "str_2 = '你说得对，但是他们在1999年发明了世界上第一款gpu，并在今天用它培养出了chatgpt，而我们在2000年全面禁止了游戏机的研发，生产和销售，并在今天痛斥他们封锁我们'\n",
    "\n",
    "str_felling_detect(model, str_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "732fbd2c-2f31-477c-bcc7-13f3406199be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10, label: 0 data: 我看过朋友的还可以，但是我订的书迟迟未到已有半个月，都没有收到打电话也没有用，以后你们订书一定要考虑好！当当实在是太慢了\n",
      "tensor([[0.9973, 0.0027]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "0 负面情感输出\n",
      "\n",
      "11, label: 1 data: 还不错，设施稍微有点旧但是可以接收，但是606的价格还不含早餐有点高了。楼下的商场和超市很方便。下次来还会选择这家。\n",
      "tensor([[0.0091, 0.9909]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "1 正面情感输出\n",
      "\n",
      "12, label: 1 data: 轻便，方便携带，性能也不错，能满足平时的工作需要，对出差人员来说非常不错\n",
      "tensor([[0.0174, 0.9826]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "1 正面情感输出\n",
      "\n",
      "13, label: 1 data: 入住的是度假区的豪华海景房,前台给了5楼(最高6楼),然后差不多100%的海景,虽然是挂牌5星的,但是本人觉得是4星的标准,和我后来入住的5星喜来登差了蛮多的,不过整体来说还是符合他家的价钱的.\n",
      "tensor([[0.1718, 0.8282]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "1 正面情感输出\n",
      "\n",
      "14, label: 0 data: 1.模具有摄像头的位置，但是没有摄像头。 2.做工一般。 3.说明书和驱动都是电子版。 4.没有预装XP系统。\n",
      "tensor([[0.9682, 0.0318]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "0 负面情感输出\n",
      "\n",
      "15, label: 0 data: 送的内胆包有点不好，还有外接电源中间连接处无法全部插入。续航时间也没有标称的那么长，希望京东能注意宣传的真实性。\n",
      "tensor([[0.9531, 0.0469]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "0 负面情感输出\n",
      "\n",
      "16, label: 1 data: 这是我第1次给全五星哦^_^超级快!这是最快收到书的一次了.我是中午的时候订的,结果第2天上午就收到了,算了一下,1天的时间都还没到呢!在此,感激下当当的服务...我的确是很急需这本书呢.关于书的本身,也很不错.内容还是很丰富的,值得推荐,对于训练和培养逻辑思维套式有一定的帮助,推荐一下~还有祝朋友们都面试成功,哈哈哈~\n",
      "tensor([[0.0457, 0.9543]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "1 正面情感输出\n",
      "\n",
      "17, label: 0 data: 很好的地理位置，一蹋糊涂的服务，萧条的酒店。\n",
      "tensor([[0.9207, 0.0793]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "0 负面情感输出\n",
      "\n",
      "18, label: 1 data: 漂亮（老婆认为的），性价比高。电池很棒，能用4～6个小时，兼容性还行，拿到手直接重装了WIN7，基本不需要任何驱动，除了快捷键。\n",
      "tensor([[0.0186, 0.9814]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "1 正面情感输出\n",
      "\n",
      "19, label: 0 data: 内存太小，偶配了2根“金条”，目前兼容。但不知道是内存不兼容还是什么，有时会听到硬盘“咔咔”运行的声音。预置系统下Office是2007试用版，偶自装2003，则每次启动弹出正版增值计划窗口，很麻烦！\n",
      "tensor([[0.9586, 0.0414]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "0 负面情感输出\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 20):\n",
    "    \n",
    "    label = dataset[i][1]\n",
    "    data_str = dataset[i][0]\n",
    "    \n",
    "    \n",
    "    print('%s, label: %s data: %s' % (i, label,  data_str))\n",
    "    \n",
    "    str_felling_detect(model, data_str)\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb96aad-315b-4987-b811-7a1d43f01ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
