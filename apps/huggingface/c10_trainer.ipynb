{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89f9a593-6d1c-49fa-9df8-ec59c3fd8335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "#加载分词工具\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab75f801-7271-4f20-aaf1-1e39fb2d557c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mylady/code/python/DL-pytorch/apps/huggingface/data/glue_sst2/train/cache-a440844e75f8838e_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/mylady/code/python/DL-pytorch/apps/huggingface/data/glue_sst2/validation/cache-efcadb6d9ecf7b0a_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/mylady/code/python/DL-pytorch/apps/huggingface/data/glue_sst2/test/cache-b26b14726e876062_*_of_00004.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "#加载数据集\n",
    "#从网络加载\n",
    "#datasets = load_dataset(path='glue', name='sst2')\n",
    "\n",
    "#从本地磁盘加载数据\n",
    "datasets = load_from_disk('./data/glue_sst2')\n",
    "\n",
    "\n",
    "#分词\n",
    "def f(data):\n",
    "    return tokenizer(\n",
    "        data['sentence'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=30,\n",
    "    )\n",
    "\n",
    "\n",
    "datasets = datasets.map(f, batched=True, batch_size=1000, num_proc=4)\n",
    "\n",
    "# 取数据子集，否则数据太多跑不动\n",
    "dataset_train = datasets['train'].shuffle().select(range(1000))\n",
    "dataset_test = datasets['validation'].shuffle().select(range(200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456a8ad2-742d-4ee8-a078-050d48f8e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "947e36fb-4595-4100-887d-50740c57f21d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d52c7f8-5e47-49aa-a1cc-25b25313be83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10831.181\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "#加载模型\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'bert-base-cased',\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "\n",
    "print(sum([i.nelement() for i in model.parameters()]) / 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13c48524-489c-4918-a787-4ed1c15faecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from transformers.trainer_utils import EvalPrediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f8cb151-2639-4f35-8887-ac0b39f965b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install scikit-learn\n",
    "\n",
    "'''\n",
    "开启代理:\n",
    "export https_proxy=127.0.0.1:7890\n",
    "export http_proxy=127.0.0.1:7890\n",
    "\n",
    "\n",
    "重启服务:\n",
    "jupyter-lab --allow-root --ip=0.0.0.0 --port=8888\n",
    "'''\n",
    "# 加载评价函数\n",
    "# 有时会因为网络问题卡主,反复尝试会成功的\n",
    "metric = load_metric('accuracy')\n",
    "\n",
    "\n",
    "# metric = load_metric('/home/mylady/.cache/huggingface/datasets/downloads/accuracy.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "058e8839-7882-4428-8807-9ee4a0d2500c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 定义评价函数\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    logits = logits.argmax(axis=1)\n",
    "    return metric.compute(predictions=logits, references=labels)\n",
    "\n",
    "\n",
    "# 模拟测试输出\n",
    "eval_pred = EvalPrediction(\n",
    "    predictions=np.array([[0, 1], [2, 3], [4, 5], [6, 7]]),\n",
    "    label_ids=np.array([1, 1, 1, 1]),\n",
    ")\n",
    "\n",
    "compute_metrics(eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "837a71b3-288a-421a-b51e-cc9c2c2ed1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "# 初始化训练参数\n",
    "args = TrainingArguments(output_dir='./output_dir',\n",
    "                         evaluation_strategy='epoch',\n",
    "                         no_cuda=True)\n",
    "\n",
    "\n",
    "args.num_train_epochs = 1\n",
    "args.learning_rate = 1e-4\n",
    "args.weight_decay = 1e-2\n",
    "args.per_device_eval_batch_size = 32\n",
    "args.per_device_train_batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d015db07-ad68-4b9c-8d0e-1a33c18b83df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6868857741355896,\n",
       " 'eval_accuracy': 0.535,\n",
       " 'eval_runtime': 2.3954,\n",
       " 'eval_samples_per_second': 83.494,\n",
       " 'eval_steps_per_second': 2.922}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 初始化训练器\n",
    "trainer = Trainer(model=model,\n",
    "                  args=args,\n",
    "                  train_dataset=dataset_train,\n",
    "                  eval_dataset=dataset_test,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                 )\n",
    "\n",
    "# 评价模型\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b85041f3-0877-4694-81e1-798e9c2ce596",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mylady/.virtualenvs/dl-pytorch/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:42, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.396098</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=63, training_loss=0.5112935626317584, metrics={'train_runtime': 43.0955, 'train_samples_per_second': 23.204, 'train_steps_per_second': 1.462, 'total_flos': 15416663400000.0, 'train_loss': 0.5112935626317584, 'epoch': 1.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ae15ed9-2a45-43ba-bde6-68c6bd7f0b67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3960981070995331,\n",
       " 'eval_accuracy': 0.825,\n",
       " 'eval_runtime': 1.7252,\n",
       " 'eval_samples_per_second': 115.931,\n",
       " 'eval_steps_per_second': 4.058,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 评价模型\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7a91d17-61a2-4473-b662-d3f438abacca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "\n",
    "save_model_path = './output_dir'\n",
    "trainer.save_model(output_dir=save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e36c5-8f12-4a51-8ece-e0a2630fadf7",
   "metadata": {},
   "source": [
    "## collate_fn 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5deb7fe8-6b54-46da-81cb-73b252e92d58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    label = [i['label'] for i in data]\n",
    "    input_ids = [i['input_ids'] for i in data]\n",
    "    token_type_ids = [i['token_type_ids'] for i in data]\n",
    "    attention_mask = [i['attention_mask'] for i in data]\n",
    "\n",
    "    label = torch.LongTensor(label)\n",
    "    input_ids = torch.LongTensor(input_ids)\n",
    "    token_type_ids = torch.LongTensor(token_type_ids)\n",
    "    attention_mask = torch.LongTensor(attention_mask)\n",
    "\n",
    "    return label, input_ids, token_type_ids, attention_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18d5e4e3-30f8-4895-9a55-d0d3e5656f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 0, 1, 0]),\n",
       " tensor([[  101,  2276,  8144,  1104,  9163,   118,   118,  1105,  3254,  1643,\n",
       "          17432,   118,   118,  1120, 12686,  9022, 15648,  1110,   170,  5871,\n",
       "           8674,  1158,  3362,  1115,  4642,  1106,  1587,  1104,  1103,   102],\n",
       "         [  101,  2257,   117,  4509,  1105, 12678, 14255,  4704, 25981,  1158,\n",
       "            119,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101,  1111,  1103,  1148,  1159,  1107,  1201,   117,  1260, 11437,\n",
       "           2180, 11902,  1116,  1996, 15962,   117,  3229,  1272,  1119,   112,\n",
       "            188,  1151, 14030,  1118,  1103,  3110,  1250,  1104,  1117,   102],\n",
       "         [  101,  1104,  1736,   117,  1118,  1167,  7649, 12307,  1122,   112,\n",
       "            188,  1253,  2385,  2213,   119,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 数据加载器\n",
    "loader_test = torch.utils.data.DataLoader(dataset=dataset_test,\n",
    "                                          batch_size=4,\n",
    "                                          collate_fn=collate_fn,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)\n",
    "\n",
    "for i, (label, input_ids, token_type_ids, attention_mask) in enumerate(loader_test):\n",
    "    \n",
    "    break\n",
    "\n",
    "label, input_ids, token_type_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2678472e-3a9b-4196-8be9-47dcf7b58aef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "#测试\n",
    "def test_v1():\n",
    "    \n",
    "    # 加载参数\n",
    "    model.load_state_dict(torch.load('./output_dir/pytorch_model.bin'))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # 运算\n",
    "    out = model(input_ids=input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask)\n",
    "\n",
    "    #[4, 2] -> [4]\n",
    "    out = out['logits'].argmax(dim=1)\n",
    "\n",
    "    correct = (out == label).sum().item()\n",
    "\n",
    "    return correct / len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "163541bf-4b30-40b9-9bbb-bf16ea49f3f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 开始测试\n",
    "test_v1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f447b0-4aa6-4292-a421-e852af9547ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
