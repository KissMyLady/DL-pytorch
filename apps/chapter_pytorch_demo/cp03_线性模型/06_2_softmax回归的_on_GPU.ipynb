{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c820bf90-33da-44fd-b635-c8b195b14b78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3861568-bfd1-442c-a221-df4613caa2ee",
   "metadata": {},
   "source": [
    "## 3.6.1 获取和读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112fa044-6172-4653-a956-b257e92eb63c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size, resize=None, root='~/Datasets/FashionMNIST'):\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "        pass\n",
    "\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=root, \n",
    "        train=True, \n",
    "        download=False, \n",
    "        transform=transform\n",
    "    )\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=root, \n",
    "        train=False, \n",
    "        download=False, \n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    if sys.platform.startswith('win'):\n",
    "        num_workers = 0  # 0表示不用额外的进程来加速读取数据\n",
    "    else:\n",
    "        num_workers = 4\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(\n",
    "        mnist_train, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    test_iter = torch.utils.data.DataLoader(\n",
    "        mnist_test, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "263c265d-3fdc-4caf-9551-62ea89ebcecf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /mnt/g1t/ai_data/Datasets_on_HHD/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b62b6c1757445b692f53a655ec011b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /mnt/g1t/ai_data/Datasets_on_HHD/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to /mnt/g1t/ai_data/Datasets_on_HHD/FashionMNIST/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /mnt/g1t/ai_data/Datasets_on_HHD/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acea03a082e4daab428a2fbb23427e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /mnt/g1t/ai_data/Datasets_on_HHD/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /mnt/g1t/ai_data/Datasets_on_HHD/FashionMNIST/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /mnt/g1t/ai_data/Datasets_on_HHD/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c352330bb44374bd34ffb15c167c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /mnt/g1t/ai_data/Datasets_on_HHD/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /mnt/g1t/ai_data/Datasets_on_HHD/FashionMNIST/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /mnt/g1t/ai_data/Datasets_on_HHD/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935ad709692048feb1b5921ea5aec30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /mnt/g1t/ai_data/Datasets_on_HHD/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /mnt/g1t/ai_data/Datasets_on_HHD/FashionMNIST/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "\n",
    "dataRoot = '/mnt/g1t/ai_data/Datasets_on_HHD/FashionMNIST'\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, root=dataRoot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1abbf48-3136-4d87-936d-4deea1539dcd",
   "metadata": {},
   "source": [
    "## 3.6.2 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12c74a19-2a02-403b-a1c0-b630664277f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "W = torch.tensor(np.random.normal(0, 0.01, (num_inputs, num_outputs)), \n",
    "                 device=device,\n",
    "                 dtype=torch.float\n",
    "                )\n",
    "\n",
    "b = torch.zeros(num_outputs, \n",
    "                device=device,\n",
    "                dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25564fb3-e6a0-4d91-9f63-04774a7ab3fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.requires_grad_(requires_grad=True)\n",
    "b.requires_grad_(requires_grad=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd136d86-90f6-4697-87c3-0e2a60732e57",
   "metadata": {},
   "source": [
    "## 3.6.3 实现softmax运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00ad3b14-e8d6-4584-8ca0-f8ae71ffac70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 7, 9]])\n",
      "tensor([[ 6],\n",
      "        [15]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[1, 2, 3], [4, 5, 6]], \n",
    "                )\n",
    "\n",
    "\n",
    "print(X.sum(dim=0, keepdim=True))\n",
    "print(X.sum(dim=1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6704b880-6890-40d6-b2d5-30894716b7a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    X_exp = X.exp().to(device)\n",
    "    partition = X_exp.sum(dim=1, keepdim=True).to(device)\n",
    "    return X_exp / partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9c06053-7990-47af-8a70-e16782a01f16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2436, 0.1905, 0.1415, 0.1775, 0.2469],\n",
      "        [0.2413, 0.2236, 0.1923, 0.1494, 0.1933]], device='cuda:0') tensor([1., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((2, 5)).to(device)\n",
    "X_prob = softmax(X).to(device)\n",
    "\n",
    "print(X_prob, X_prob.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea510a59-4882-499e-b912-794c8aed2b70",
   "metadata": {},
   "source": [
    "## 3.6.4 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42589b9a-095e-4b5e-b6ea-1449649bd48d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    X = X.to(device)\n",
    "    \n",
    "    return softmax(torch.mm(X.view((-1, num_inputs)).to(device), \n",
    "                            W).to(device) + b.to(device)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ae538-8556-4d7b-8869-a637f11fcf55",
   "metadata": {},
   "source": [
    "## 3.6.5 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c66ae0bb-2c43-451f-a343-22e7ba343d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000],\n",
       "        [0.5000]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]]).to(device)\n",
    "\n",
    "y = torch.LongTensor([0, 2]).to(device)\n",
    "\n",
    "y_hat.gather(1, y.view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "123d2a08-272a-4fde-84fc-a28f1904f92a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "def cross_entropy(y_hat, y):\n",
    "    y_hat = y_hat.to(device)\n",
    "    y = y.to(device)\n",
    "    return - torch.log(y_hat.gather(1, y.view(-1, 1))).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab81ec40-bf39-4803-ad07-1a388f413c64",
   "metadata": {},
   "source": [
    "## 3.6.6 计算分类准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f11a5f7-6597-4648-a4c7-4f537e60a536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    return (y_hat.argmax(dim=1) == y).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f837963-a343-4c47-97d0-d917dec8e9be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(y_hat, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6201ea1-e1bb-4098-b10e-f1e2d589663a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用。\n",
    "# 该函数将被逐步改进：它的完整实现将在“图像增广”一节中描述\n",
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for X, y in data_iter:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return (acc_sum / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7ffaa0a-3461-4c1e-ad2e-a232470d582d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1071\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_accuracy(test_iter, net))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d33a01f-d363-4c4f-b2c7-9ed49d6cfce6",
   "metadata": {},
   "source": [
    "## 3.6.7 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9b4e905-c249-4acf-9992-8a2aaf7d35f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):\n",
    "    # 为了和原书保持一致，这里除以了batch_size，但是应该是不用除的，因为一般用PyTorch计算loss时就默认已经\n",
    "    # 沿batch维求了平均了。\n",
    "    for param in params:\n",
    "        # 注意这里更改param时用的param.data\n",
    "        param.data -= lr * param.grad / batch_size \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3842ad91-8315-4be1-82e2-42c66ac35697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs, lr = 20, 0.1\n",
    "\n",
    "\n",
    "# 本函数已保存在d2lzh包中方便以后使用\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,\n",
    "              params=None, lr=None, optimizer=None):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        \n",
    "        for X, y in train_iter:\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).sum()\n",
    "            \n",
    "            # 梯度清零\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "\n",
    "            l.backward()\n",
    "            if optimizer is None:\n",
    "                sgd(params, lr, batch_size)\n",
    "            else:\n",
    "                optimizer.step()  # “softmax回归的简洁实现”一节将用到\n",
    "                pass\n",
    "            \n",
    "            train_l_sum += l.item()\n",
    "            \n",
    "            #target = np.array(train_acc_sum).astype(float)\n",
    "            #target = torch.from_numpy(target)\n",
    "            #train_acc_sum = target.to(device)\n",
    "            # print(train_acc_sum)\n",
    "            \n",
    "            y_hat = y_hat.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            pass\n",
    "    \n",
    "        # test_acc = evaluate_accuracy(test_iter, net)\n",
    "        test_acc = -1.0\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f97dc48-1e1f-4458-8e97-878441e44519",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.7868, train acc 0.749, test acc -1.000\n",
      "epoch 2, loss 0.5700, train acc 0.813, test acc -1.000\n",
      "epoch 3, loss 0.5248, train acc 0.825, test acc -1.000\n",
      "epoch 4, loss 0.5010, train acc 0.832, test acc -1.000\n",
      "epoch 5, loss 0.4850, train acc 0.837, test acc -1.000\n",
      "epoch 6, loss 0.4734, train acc 0.841, test acc -1.000\n",
      "epoch 7, loss 0.4657, train acc 0.843, test acc -1.000\n",
      "epoch 8, loss 0.4580, train acc 0.845, test acc -1.000\n",
      "epoch 9, loss 0.4526, train acc 0.846, test acc -1.000\n",
      "epoch 10, loss 0.4470, train acc 0.848, test acc -1.000\n",
      "epoch 11, loss 0.4438, train acc 0.849, test acc -1.000\n",
      "epoch 12, loss 0.4400, train acc 0.850, test acc -1.000\n",
      "epoch 13, loss 0.4358, train acc 0.851, test acc -1.000\n",
      "epoch 14, loss 0.4342, train acc 0.852, test acc -1.000\n",
      "epoch 15, loss 0.4307, train acc 0.853, test acc -1.000\n",
      "epoch 16, loss 0.4288, train acc 0.853, test acc -1.000\n",
      "epoch 17, loss 0.4262, train acc 0.855, test acc -1.000\n",
      "epoch 18, loss 0.4244, train acc 0.856, test acc -1.000\n",
      "epoch 19, loss 0.4223, train acc 0.857, test acc -1.000\n",
      "epoch 20, loss 0.4203, train acc 0.857, test acc -1.000\n",
      "耗时:  11.916711330413818\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# 开始训练\n",
    "train_ch3(net, \n",
    "          train_iter,\n",
    "          test_iter, \n",
    "          cross_entropy, \n",
    "          num_epochs, \n",
    "          batch_size, \n",
    "          [W, b], \n",
    "          lr\n",
    "         )\n",
    "\n",
    "print(\"耗时: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca960d2-5345-46f5-9619-81b8de3c6341",
   "metadata": {},
   "source": [
    "## 3.6.8 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcb7b961-9d46-4620-bf9f-ba8e217c3e38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f1716442e50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dadfa340-30f9-4e4a-811a-4972092a89a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fashion_mnist_labels(labels):\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6413a1b3-5460-4761-806a-771b9568deff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_num: 8398\n",
      "error_num: 1602\n",
      "正确率: 0.8398\n"
     ]
    }
   ],
   "source": [
    "correct_num = 0\n",
    "error_num = 0\n",
    "\n",
    "for i, value in enumerate(test_iter):\n",
    "    X, y = value[0].to(device), value[1].to(device)\n",
    "    \n",
    "    y = y.cpu()\n",
    "    # X = X.cpu()\n",
    "    \n",
    "    true_labels = get_fashion_mnist_labels(y.numpy())\n",
    "    pred_labels = get_fashion_mnist_labels(net(X).cpu().argmax(dim=1).numpy())\n",
    "\n",
    "    # titles = [true + '\\n' + pred for true, pred in zip(true_labels, pred_labels)]\n",
    "\n",
    "    # d2l.show_fashion_mnist(X[0:9], titles[0:9])\n",
    "    \n",
    "    for true, pred in zip(true_labels, pred_labels):\n",
    "        if pred == true:\n",
    "            correct_num += 1\n",
    "        else:\n",
    "            error_num += 1\n",
    "        pass\n",
    "\n",
    "    \n",
    "print(\"correct_num: %s\" % correct_num)\n",
    "print(\"error_num: %s\" % error_num)\n",
    "print(\"正确率: %s\" % (correct_num / (correct_num+ error_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c918620-b234-48f3-bde1-deac0b828705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
