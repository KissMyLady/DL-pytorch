{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daa74040-dbe8-4820-8a38-6e370b0d44ac",
   "metadata": {},
   "source": [
    "# 4.6 GPU计算\n",
    "\n",
    "到目前为止，我们一直在使用CPU计算。对复杂的神经网络和大规模的数据来说，使用CPU来计算可能不够高效。在本节中，我们将介绍如何使用单块NVIDIA GPU来计算。所以需要确保已经安装好了PyTorch GPU版本。准备工作都完成后，下面就可以通过`nvidia-smi`命令来查看显卡信息了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "251161fd-5066-4e46-8439-5bc2a8631f02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 16 15:30:54 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 30%   34C    P2    44W / 220W |   1027MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       916      G   /usr/lib/xorg/Xorg                  9MiB |\n",
      "|    0   N/A  N/A      1277      G   /usr/bin/gnome-shell                3MiB |\n",
      "|    0   N/A  N/A      4788      C   ...nvs/dl-pytorch/bin/python     1010MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi  # 对Linux/macOS用户有效"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdce215-02c0-4da5-821e-e1f20799b536",
   "metadata": {},
   "source": [
    "## 4.6.1 计算设备\n",
    "\n",
    "PyTorch可以指定用来存储和计算的设备，如使用内存的CPU或者使用显存的GPU。默认情况下，PyTorch会将数据创建在内存，然后利用CPU来计算。\n",
    "\n",
    "用`torch.cuda.is_available()`查看GPU是否可用:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f93ca7-65d2-490b-b77d-62f5abbce604",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.cuda.is_available() # 输出 True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "980236f2-f59f-4d11-b1c7-99ffa3e276bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看GPU数量\n",
    "torch.cuda.device_count() # 输出 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636dafcf-998a-4c40-920c-0e406728a624",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看当前GPU索引号，索引号从0开始：\n",
    "torch.cuda.current_device() # 输出 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc46328-f56d-433e-81a2-bab661354ef6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3070'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据索引号查看GPU名字:\n",
    "torch.cuda.get_device_name(0) # 输出 'NVIDIA GeForce RTX 3070'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1df8e1-533e-4afe-9b7d-f1864fd0feb1",
   "metadata": {},
   "source": [
    "## 4.6.2 `Tensor`的GPU计算\n",
    "\n",
    "默认情况下，`Tensor`会被存在内存上。因此，之前我们每次打印`Tensor`的时候看不到GPU相关标识。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02be93a1-386c-4158-ae12-714cd52f244f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5b1574-f215-4f01-a101-362633b62d47",
   "metadata": {},
   "source": [
    "使用`.cuda()`可以将CPU上的`Tensor`转换（复制）到GPU上。如果有多块GPU，我们用`.cuda(i)`来表示第 $i$ 块GPU及相应的显存（$i$从0开始）且`cuda(0)`和`cuda()`等价。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c37304a3-71e1-4985-8714-81db978f1c52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.cuda(0)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f25b86-a70b-4891-aa4c-a8eb56b7b0ae",
   "metadata": {},
   "source": [
    "我们可以通过`Tensor`的`device`属性来查看该`Tensor`所在的设备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36f61f9c-4d52-473b-a2c3-17cf1af01af0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234c5f2-e133-4ec5-ad7b-5efecf04ae4c",
   "metadata": {},
   "source": [
    "我们可以直接在创建的时候就指定设备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cf9aeec-5e62-4706-88c6-a227e8ce7b7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "x = torch.tensor([1, 2, 3], device=device)\n",
    "\n",
    "\n",
    "# or\n",
    "x = torch.tensor([1, 2, 3]).to(device)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97904955-9f2d-45f3-a945-858cee67650f",
   "metadata": {},
   "source": [
    "如果对在GPU上的数据进行运算，那么结果还是存放在GPU上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54cd918f-9982-4f9f-a161-844ca9fbab16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x**2\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8899fb5-0bb9-4bb8-8a97-086b018d4d53",
   "metadata": {},
   "source": [
    "需要注意的是，存储在不同位置中的数据是不可以直接进行计算的。即存放在CPU上的数据不可以直接与存放在GPU上的数据进行运算，位于不同GPU上的数据也是不能直接进行计算的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29e89e7d-d2f9-4f45-ad15-676cdc18288a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "z = y + x.cpu()  # 会报错:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1041ad5-41df-415d-a5c3-ca87e60132e8",
   "metadata": {},
   "source": [
    "## 4.6.3 模型的GPU计算\n",
    "\n",
    "同`Tensor`类似，PyTorch模型也可以通过`.cuda`转换到GPU上。我们可以通过检查模型的参数的`device`属性来查看存放模型的设备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec4a165e-b117-4423-b066-be3673f4f4b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7fa4f221b040>\n",
      "\n",
      "[Parameter containing:\n",
      "tensor([[ 0.1344, -0.1416,  0.2403]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2868], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "net = nn.Linear(3, 1)\n",
    "\n",
    "print(net.parameters())\n",
    "\n",
    "print('')\n",
    "\n",
    "print(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52a969cf-7e71-45b9-a8b0-12f1735198a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())[0].device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4749ea80-1d5d-4754-bcac-45398bb4d755",
   "metadata": {},
   "source": [
    "可见模型在CPU上，将其转换到GPU上:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90ccd720-0298-4c15-832a-768ea8aea338",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.cuda()\n",
    "list(net.parameters())[0].device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf554bc1-a7a1-4cdd-9a87-3b45af4cb287",
   "metadata": {},
   "source": [
    "同样的，我么需要保证模型输入的`Tensor`和模型都在同一设备上，否则会报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18a363ad-f957-4e36-8047-766d1b82860e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1367],\n",
       "        [-0.1584]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2,3).cuda()\n",
    "\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612cfde5-5fe5-4de2-bd5f-33b402233822",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "* PyTorch可以指定用来存储和计算的设备，如使用内存的CPU或者使用显存的GPU。在默认情况下，PyTorch会将数据创建在内存，然后利用CPU来计算。\n",
    "* PyTorch要求计算的所有输入数据都在内存或同一块显卡的显存上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c90cf9-c13d-4ebb-869e-b2c3904e887e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
