{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4547e36-40fb-429f-af97-257fd9df2f91",
   "metadata": {},
   "source": [
    "# 循环神经网络\n",
    "\n",
    "*循环神经网络*（recurrent neural networks，RNNs）\n",
    "是具有隐状态的神经网络。\n",
    "在介绍循环神经网络模型之前，\n",
    "我们首先回顾 :numref:`sec_mlp`中介绍的多层感知机模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2595e58-9a91-4bb8-b016-e2d5a572bcee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3284ff4-ccfd-4c2b-b14f-b6d81eeffa9d",
   "metadata": {},
   "source": [
    "我们刚才提到，隐状态中\n",
    "$\\mathbf{X}_t \\mathbf{W}_{xh} + \\mathbf{H}_{t-1} \\mathbf{W}_{hh}$的计算，\n",
    "相当于$\\mathbf{X}_t$和$\\mathbf{H}_{t-1}$的拼接\n",
    "与$\\mathbf{W}_{xh}$和$\\mathbf{W}_{hh}$的拼接的矩阵乘法。\n",
    "虽然这个性质可以通过数学证明，\n",
    "但在下面我们使用一个简单的代码来说明一下。\n",
    "首先，我们定义矩阵`X`、`W_xh`、`H`和`W_hh`，\n",
    "它们的形状分别为$(3，1)$、$(1，4)$、$(3，4)$和$(4，4)$。\n",
    "分别将`X`乘以`W_xh`，将`H`乘以`W_hh`，\n",
    "然后将这两个乘法相加，我们得到一个形状为$(3，4)$的矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5eb9794f-eb31-4e13-814b-09ef52e10fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0408],\n",
      "        [-1.7170],\n",
      "        [-0.2907]])\n",
      "tensor([[-0.0349,  1.0426, -0.0222,  0.8779]])\n"
     ]
    }
   ],
   "source": [
    "# 输入 (X + W_xh) + (H + W_hh)\n",
    "X    = torch.normal(0, 1, (3, 1))\n",
    "W_xh = torch.normal(0, 1, (1, 4))\n",
    "\n",
    "\n",
    "H    = torch.normal(0, 1, (3, 4))\n",
    "W_hh = torch.normal(0, 1, (4, 4))\n",
    "\n",
    "print(X)\n",
    "print(W_xh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2365096f-6c7d-4522-832c-cf925096f055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0308,  2.1261, -0.0737, -0.7566],\n",
      "        [-0.7136,  0.6886,  1.0068, -1.2115],\n",
      "        [ 0.5865,  0.8969,  0.1104, -1.7619]])\n",
      "tensor([[ 0.8581, -0.5493,  0.8426,  0.2695],\n",
      "        [ 0.9408, -0.1433,  1.1685,  1.3606],\n",
      "        [-1.6592, -0.6335, -0.4893, -1.3101],\n",
      "        [-0.4059, -0.2835, -0.2765,  0.5845]])\n"
     ]
    }
   ],
   "source": [
    "print(H)\n",
    "print(W_hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91a010ae-7c92-4dbd-8242-d8c49e2d9451",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.4047, -0.0692,  2.7045,  2.5028],\n",
       "        [-1.0832, -1.7912,  0.0837, -2.7898],\n",
       "        [ 1.8893, -0.3242,  1.9818, -0.0512]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵拼接\n",
    "torch.matmul(X, W_xh) + torch.matmul(H, W_hh) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b0ba3-9308-4616-883b-d0f0293b9881",
   "metadata": {},
   "source": [
    "现在，我们沿列（轴1）拼接矩阵`X`和`H`，\n",
    "沿行（轴0）拼接矩阵`W_xh`和`W_hh`。\n",
    "这两个拼接分别产生形状$(3, 5)$和形状$(5, 4)$的矩阵。\n",
    "再将这两个拼接的矩阵相乘，\n",
    "我们得到与上面相同形状$(3, 4)$的输出矩阵。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a7f8e60-365e-43fd-9c48-e353b7e65f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0408],\n",
      "        [-1.7170],\n",
      "        [-0.2907]])\n",
      "tensor([[-0.0308,  2.1261, -0.0737, -0.7566],\n",
      "        [-0.7136,  0.6886,  1.0068, -1.2115],\n",
      "        [ 0.5865,  0.8969,  0.1104, -1.7619]])\n",
      "拼接: \n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(H)\n",
    "print(\"拼接: \")\n",
    "res1 = torch.cat((X, H), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "241cd64c-c309-40ff-8382-cd825fac743f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0349,  1.0426, -0.0222,  0.8779]])\n",
      "tensor([[ 0.8581, -0.5493,  0.8426,  0.2695],\n",
      "        [ 0.9408, -0.1433,  1.1685,  1.3606],\n",
      "        [-1.6592, -0.6335, -0.4893, -1.3101],\n",
      "        [-0.4059, -0.2835, -0.2765,  0.5845]])\n",
      "拼接: \n"
     ]
    }
   ],
   "source": [
    "print(W_xh)\n",
    "print(W_hh)\n",
    "print(\"拼接: \")\n",
    "res2 = torch.cat((W_xh, W_hh), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7121d53a-7555-422b-898a-ddfec6a9d51b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.4047, -0.0692,  2.7045,  2.5028],\n",
       "        [-1.0832, -1.7912,  0.0837, -2.7898],\n",
       "        [ 1.8893, -0.3242,  1.9818, -0.0512]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵相乘\n",
    "torch.matmul(res1, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a934da84-05e2-4157-8b8d-94b3596d01c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
