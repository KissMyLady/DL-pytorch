{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8fd75b6-2abf-40ab-a776-281d408fd41c",
   "metadata": {},
   "source": [
    "# 2.3 自动求梯度\n",
    "\n",
    "在深度学习中，我们经常需要对函数求梯度（gradient）。PyTorch提供的[autograd](https://pytorch.org/docs/stable/autograd.html)包能够根据输入和前向传播过程自动构建计算图，并执行反向传播。本节将介绍如何使用autograd包来进行自动求梯度的有关操作。\n",
    "\n",
    "## 2.3.1 概念\n",
    "\n",
    "上一节介绍的`Tensor`是这个包的核心类，如果将其属性`.requires_grad`设置为`True`，它将开始追踪(track)在其上的所有操作（这样就可以利用链式法则进行梯度传播了）。完成计算后，可以调用`.backward()`来完成所有梯度计算。此`Tensor`的梯度将累积到`.grad`属性中。\n",
    "\n",
    "> 注意在`y.backward()`时，如果`y`是标量，则不需要为`backward()`传入任何参数；否则，需要传入一个与`y`同形的`Tensor`。解释见 2.3.2 节。\n",
    "\n",
    "如果不想要被继续追踪，可以调用`.detach()`将其从追踪记录中分离出来，这样就可以防止将来的计算被追踪，这样梯度就传不过去了。此外，还可以用`with torch.no_grad()`将不想被追踪的操作代码块包裹起来，这种方法在评估模型的时候很常用，因为在评估模型时，我们并不需要计算可训练参数（`requires_grad=True`）的梯度。\n",
    "\n",
    "`Function`是另外一个很重要的类。`Tensor`和`Function`互相结合就可以构建一个记录有整个计算过程的有向无环图（DAG）。每个`Tensor`都有一个`.grad_fn`属性，该属性即创建该`Tensor`的`Function`, 就是说该`Tensor`是不是通过某些运算得到的，若是，则`grad_fn`返回一个与这些运算相关的对象，否则是None。\n",
    "\n",
    "下面通过一些例子来理解这些概念。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "402adbce-256f-492a-90cd-854c57568b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0140116d-37ab-4981-91bd-dc842a941916",
   "metadata": {},
   "source": [
    "\n",
    "## 2.3.2 `Tensor`\n",
    "\n",
    "创建一个`Tensor`并设置`requires_grad=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a301f35-eb96-4d3a-9cbe-1f3f67c30400",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "\n",
      " 打印grad_fn属性, 是不是通过某些运算得到的:  None\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "\n",
    "print(x)\n",
    "\n",
    "print('\\n 打印grad_fn属性, 是不是通过某些运算得到的: ', x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ad7384c-1b9d-4345-b10d-8af599fca2ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "\n",
      " y是通过运算得到的:  <AddBackward0 object at 0x7f54a77ba110>\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "\n",
    "print(y)\n",
    "\n",
    "print('\\n y是通过运算得到的: ', y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e2cc864-5d0c-483d-abf5-6ec3412e9542",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.is_leaf)\n",
    "\n",
    "print(y.is_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c90da26d-5ded-46ca-a1a4-e17b4e2008ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: \n",
      " tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "z: \n",
      " tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)  \n",
      "out: \n",
      " tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "\n",
    "print(\"z: \\n\", z)\n",
    "\n",
    "out = z.mean()\n",
    "print('z: \\n', z, ' \\nout: \\n', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "002bc689-7f47-456b-badc-1786f6b8f23a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / ( a - 1))\n",
    "\n",
    "print(a.requires_grad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cfe040b-613c-4468-aad1-3a5e133a1054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 15.1105,   2.1125],\n",
       "        [ -1.7425, 856.6286]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df6e0b2-fabd-4e42-aa55-7a999226b868",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SumBackward0 at 0x7f53ab275060>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = ( a * a).sum()\n",
    "\n",
    "b.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3562da-c006-4775-badf-f29afe3ccde7",
   "metadata": {},
   "source": [
    "## 2.3.3 梯度\n",
    "\n",
    "因为`out`是一个标量，所以调用`backward()`时不需要指定求导变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "913f8828-186a-4723-acd8-041889385a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + 2       #\n",
    "\n",
    "z = y * y * 3\n",
    "\n",
    "out = z.mean()  # -> 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed91133c-6592-4359-855a-263d56a95925",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out:  tensor(27., grad_fn=<MeanBackward0>)\n",
      "x:  tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "y:  tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"out: \", out)\n",
    "print(\"x: \"  , x)\n",
    "print(\"y: \"  , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9c4dec2-0a4a-42ab-85d4-8725f839a9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e942d7a-8ec7-4383-b0a7-2f1c5d92c226",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1452875-ad7a-49c1-89ea-0be2a2169033",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be1a7bcb-cb8b-4e10-8c79-a5cd2a5376e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a13e0f1-1930-4a24-b93a-c11fc623a1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.5000, 5.5000],\n",
       "        [5.5000, 5.5000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 反向传播一次\n",
    "out2 = x.sum()\n",
    "out2.backward()\n",
    "\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b50b7ab-0841-47cc-8223-c5101b33446c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3 = x.sum()\n",
    "x.grad.data.zero_()\n",
    "\n",
    "out3.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5395b5e-98a9-4ba9-ae1a-a964b8929d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a596774-af9e-48cf-be50-f0fa61c79959",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [6., 8.]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1., 2., 3., 4.], requires_grad=True)\n",
    "\n",
    "y = 2 * x\n",
    "z = y.view(2, 2)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6010b2bc-4bdc-4652-87e7-7bcd7d6a6de5",
   "metadata": {},
   "source": [
    "现在 `z` 不是一个标量，所以在调用`backward`时需要传入一个和`z`同形的权重向量进行加权求和得到一个标量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1774f0b-a34a-4ad2-8ee8-550a255a074e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0000, 0.2000, 0.0200, 0.0020])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([[1.0, 0.1], [0.01, 0.001]], dtype=torch.float)\n",
    "\n",
    "z.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c752ec59-e2ca-430e-9574-e8b99d0415e7",
   "metadata": {},
   "source": [
    "此外，如果我们想要修改`tensor`的数值，但是又不希望被`autograd`记录（即不会影响反向传播），那么我么可以对`tensor.data`进行操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1799c538-ded7-4e18-9c15-609c3b9a84e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "#print('x.data: \\n', x.data)  # 还是一个tensor\n",
    "#print('x.data.requires_grad: \\n', x.data.requires_grad)  # 独立于计算图之外\n",
    "\n",
    "# x = torch.mul(x, 2)\n",
    "\n",
    "y = torch.mul(x, 2)\n",
    "\n",
    "z = y * 100\n",
    "\n",
    "# x.data *= 100 # 只改变了值，不会记录在计算图，所以不会影响梯度传播\n",
    "\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0ea07e5-3a71-4225-9131-5593d5f0c49c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(x)  # 更改data的值也会影响tensor的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "734fb51f-7782-4f6b-9a73-008bcb7ae523",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(200.)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb202cb0-17f9-4d63-89ce-06c34ccc7e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
