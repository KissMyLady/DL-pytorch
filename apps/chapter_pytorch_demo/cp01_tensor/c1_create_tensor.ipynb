{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fbb5a0d-6cd2-41ef-9f1c-86d32e227377",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\n",
      "GPU是否可用: \t True\n",
      "GPU数量: \t 1\n",
      "GPU索引号: \t 0\n",
      "GPU名称: \t NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "cuDNN是否可用: \t 8700\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "def get_device():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    return device\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    \n",
    "    print(\"GPU是否可用: \\t\", torch.cuda.is_available())\n",
    "    \n",
    "    print(\"GPU数量: \\t\",    torch.cuda.device_count())\n",
    "    \n",
    "    print(\"GPU索引号: \\t\",   torch.cuda.current_device())\n",
    "    \n",
    "    print(\"GPU名称: \\t\",     torch.cuda.get_device_name())\n",
    "\n",
    "    print(\"cuDNN是否可用: \\t\", torch.backends.cudnn.version())  # 8500\n",
    "else:\n",
    "    print(\"warn: 当前服务器GPU不可用\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919b4518-0e12-4561-a3f3-682e3980611f",
   "metadata": {},
   "source": [
    "## 2.2.1 创建`Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d99f866-c24d-4a0e-a073-f0594b3297b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.9387e-39, 2.9388e-39, 9.1840e-40, 2.9388e-39],\n",
       "         [2.9388e-39, 1.0469e-38, 1.0102e-38, 3.6736e-39],\n",
       "         [6.5204e-39, 7.8061e-39, 2.8587e+12, 2.1338e+32],\n",
       "         [2.9388e-39, 1.0653e-38, 4.0408e-39, 1.0653e-38]],\n",
       "\n",
       "        [[1.0469e-38, 9.5510e-39, 9.0918e-39, 9.1837e-39],\n",
       "         [4.2246e-39, 1.0561e-38, 8.9082e-39, 8.9082e-39],\n",
       "         [9.9184e-39, 9.0000e-39, 9.2755e-39, 3.7653e-39],\n",
       "         [9.1841e-40, 2.9388e-39, 2.9388e-39, 2.9387e-39]],\n",
       "\n",
       "        [[2.9388e-39, 1.0286e-38, 9.6429e-39, 1.0653e-38],\n",
       "         [3.1225e-39, 7.3469e-39, 7.0836e+22, 5.3788e-39],\n",
       "         [8.4489e-39, 3.1226e-39, 2.9388e-39, 2.9388e-39],\n",
       "         [1.0653e-38, 1.0469e-38, 9.5510e-39, 9.0918e-39]],\n",
       "\n",
       "        [[9.1837e-39, 4.2246e-39, 9.2755e-39, 9.6429e-39],\n",
       "         [9.2755e-39, 9.0918e-39, 1.0745e-38, 1.0653e-38],\n",
       "         [3.7653e-39, 9.1841e-40, 2.9388e-39, 2.9388e-39],\n",
       "         [2.9387e-39, 2.9388e-39, 1.0286e-38, 9.6429e-39]],\n",
       "\n",
       "        [[1.0653e-38, 3.1225e-39, 7.3469e-39, 1.3459e+37],\n",
       "         [2.1249e+12, 2.9388e-39, 1.0653e-38, 4.0408e-39],\n",
       "         [2.9388e-39, 1.0653e-38, 1.0469e-38, 9.5510e-39],\n",
       "         [9.0918e-39, 9.1837e-39, 4.2246e-39, 1.0745e-38]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(5, 4, 4)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ae29f-40e3-4815-bba1-5f58bf892acb",
   "metadata": {},
   "source": [
    "创建一个5x3 的long 型全0的`Tensor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ff6362e-f68e-4b01-abe0-5a71e6186f23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(3, 4, 3, dtype=torch.long)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab9d37eb-0650-4e2f-9b70-91abea3b1ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c660e805-691d-40d6-9dec-6ca3a2aedec4",
   "metadata": {},
   "source": [
    "还可以通过现有的`Tensor`来创建，此方法会默认重用输入`Tensor`的一些属性，例如数据类型，除非自定义数据类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed9550c-29cc-4703-b1f8-a9c190a6783b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-0.0722, -0.0376,  0.3482],\n",
      "        [ 0.2779,  0.7696,  0.3124],\n",
      "        [ 0.3978,  0.3552,  0.2303],\n",
      "        [ 1.5174, -1.7307, -0.8435],\n",
      "        [ 0.1333,  0.0837, -0.3821]])\n",
      "size:   torch.Size([5, 3])\n",
      "shape:  torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.float64)\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)\n",
    "\n",
    "print('size:  ', x.size())\n",
    "print('shape: ', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d704c0ba-4c2b-4b49-856b-09c06bd302f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.eye(64)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "281e175a-8254-4dc3-b79c-48fbf36f4b27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4418e+00,  3.5800e-01,  1.1721e+00, -1.1008e+00,  9.3169e-01,\n",
       "         7.6637e-01, -8.6546e-02, -7.8399e-01, -1.1144e+00, -1.7153e-01,\n",
       "         4.4690e-02, -9.2580e-01,  1.5841e-01,  4.4348e-01,  5.2745e-01,\n",
       "        -1.6923e+00,  1.6283e+00,  2.5323e-01, -8.3921e-01, -1.3499e+00,\n",
       "         5.4365e-01,  1.0307e+00, -1.1154e+00, -8.8771e-01, -4.1641e-01,\n",
       "         2.6717e-01,  1.3613e-02,  1.3925e+00,  1.5686e+00, -1.2617e+00,\n",
       "         1.4933e-01,  6.1900e-02,  6.9021e-01, -5.1229e-01, -8.1467e-01,\n",
       "        -2.8275e+00,  1.1184e+00,  3.7434e-01, -5.0925e-01, -2.3269e-02,\n",
       "         1.6380e+00, -1.2588e-01,  1.1079e+00,  4.8453e-01,  6.1135e-01,\n",
       "        -2.1648e-03,  3.5612e-01, -8.7305e-01, -1.0378e+00,  1.1635e+00,\n",
       "        -5.2476e-01,  2.3020e-01,  2.1434e-01,  3.3487e-01, -4.3829e-01,\n",
       "         4.6382e-01,  1.0404e+00, -1.4902e+00, -2.0388e+00, -1.6802e+00,\n",
       "        -5.9098e-02, -2.1597e-01, -4.9333e-01, -1.4375e+00])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn(64)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a485e2a-16c9-49d8-b000-dfc0efc5ae3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9486, 0.0117, 0.9010, 0.9850, 0.2764, 0.3299, 0.5158, 0.4235, 0.8476,\n",
       "        0.9334, 0.1126, 0.3768, 0.7841, 0.7867, 0.1440, 0.8243, 0.6731, 0.6128,\n",
       "        0.3812, 0.0656, 0.7432, 0.2785, 0.1113, 0.2467, 0.0551, 0.6618, 0.7719,\n",
       "        0.0158, 0.3398, 0.4767, 0.4028, 0.1692, 0.4641, 0.8919, 0.7167, 0.5713,\n",
       "        0.5820, 0.0381, 0.5630, 0.2116, 0.4347, 0.3830, 0.5683, 0.9564, 0.2556,\n",
       "        0.2405, 0.1098, 0.6793, 0.9762, 0.7028, 0.4481, 0.0126, 0.7802, 0.4378,\n",
       "        0.4890, 0.5259, 0.6746, 0.3653, 0.6023, 0.0690, 0.7237, 0.5265, 0.8125,\n",
       "        0.4195])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(64)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f4ab828-f309-4362-8f12-7f2b33dd261f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 9, 1, 8, 7, 6, 0, 5, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randperm(10)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61b7a59-b9c9-42e9-8d5c-091d647b5800",
   "metadata": {},
   "source": [
    "## 2.2.2 操作\n",
    "\n",
    "本小节介绍`Tensor`的各种操作。\n",
    "\n",
    "### 算术操作\n",
    "\n",
    "在PyTorch中，同一种操作可能有很多种形式，下面用加法作为例子。\n",
    "\n",
    "* **加法形式一**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dbccd3c-d14a-40ce-8355-2412732f170e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9877, 0.5525, 0.7596, 0.9965],\n",
      "        [0.6894, 1.7523, 1.5193, 0.9238],\n",
      "        [1.1373, 1.0975, 0.7698, 0.7071],\n",
      "        [1.5638, 0.8873, 0.9559, 0.9408],\n",
      "        [1.7249, 0.3225, 0.9300, 0.8597]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 4)\n",
    "x = torch.rand(5, 4)\n",
    "\n",
    "\n",
    "# print(x + y)\n",
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca5bb1b-aabe-4cb8-8c46-61f99d6da02d",
   "metadata": {},
   "source": [
    "**加法形式二**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "857b1fc7-fdc8-4b4c-9e83-720e6201ed22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9877, 0.5525, 0.7596, 0.9965],\n",
      "        [0.6894, 1.7523, 1.5193, 0.9238],\n",
      "        [1.1373, 1.0975, 0.7698, 0.7071],\n",
      "        [1.5638, 0.8873, 0.9559, 0.9408],\n",
      "        [1.7249, 0.3225, 0.9300, 0.8597]])\n"
     ]
    }
   ],
   "source": [
    "res = torch.empty(5, 4)\n",
    "\n",
    "torch.add(x, y, out=res)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6975f128-d3fa-404e-9867-4308aac82ead",
   "metadata": {},
   "source": [
    "**加法形式三、inplace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f030676a-dae3-43d8-be3a-a3604231deca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9877, 0.5525, 0.7596, 0.9965],\n",
      "        [0.6894, 1.7523, 1.5193, 0.9238],\n",
      "        [1.1373, 1.0975, 0.7698, 0.7071],\n",
      "        [1.5638, 0.8873, 0.9559, 0.9408],\n",
      "        [1.7249, 0.3225, 0.9300, 0.8597]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979dbb25-6a31-437f-a87b-744eac39e331",
   "metadata": {},
   "source": [
    "### 索引\n",
    "\n",
    "我们还可以使用类似NumPy的索引操作来访问`Tensor`的一部分，需要注意的是：**索引出来的结果与原数据共享内存，也即修改一个，另一个会跟着修改。** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c378f4a5-1892-43f3-8239-f350c4f710b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5947, 0.5238, 0.4946, 0.2793],\n",
       "        [0.0976, 0.9018, 0.8776, 0.4283],\n",
       "        [0.9780, 0.4874, 0.2762, 0.4631],\n",
       "        [0.8511, 0.0607, 0.4643, 0.8542],\n",
       "        [0.9201, 0.1615, 0.1940, 0.0256]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e23d8a4e-512f-4e2c-abf4-af8f3369e3c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5947, 1.5238, 1.4946, 1.2793])\n",
      "tensor([1.5947, 1.5238, 1.4946, 1.2793])\n"
     ]
    }
   ],
   "source": [
    "y = x[0, :]\n",
    "\n",
    "y += 1\n",
    "print(y)\n",
    "\n",
    "print(x[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f880ce04-9b52-411a-8b2f-32559a0ad8cc",
   "metadata": {},
   "source": [
    "### 改变形状\n",
    "\n",
    "用`view()`来改变`Tensor`的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4e08313-166b-4d81-95d1-83314ea489ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5947, 1.5238, 1.4946, 1.2793],\n",
       "        [0.0976, 0.9018, 0.8776, 0.4283],\n",
       "        [0.9780, 0.4874, 0.2762, 0.4631],\n",
       "        [0.8511, 0.0607, 0.4643, 0.8542],\n",
       "        [0.9201, 0.1615, 0.1940, 0.0256]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe7e17dc-326c-4899-942a-4063729caa97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5947, 1.5238, 1.4946, 1.2793, 0.0976, 0.9018, 0.8776, 0.4283, 0.9780,\n",
      "        0.4874, 0.2762, 0.4631, 0.8511, 0.0607, 0.4643, 0.8542, 0.9201, 0.1615,\n",
      "        0.1940, 0.0256])\n",
      "torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "y = x.view(20)\n",
    "\n",
    "print(y)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6606e1fa-ae05-44f6-99fe-b51bc8dbe036",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5947, 1.5238, 1.4946, 1.2793, 0.0976],\n",
      "        [0.9018, 0.8776, 0.4283, 0.9780, 0.4874],\n",
      "        [0.2762, 0.4631, 0.8511, 0.0607, 0.4643],\n",
      "        [0.8542, 0.9201, 0.1615, 0.1940, 0.0256]])\n",
      "torch.Size([4, 5])\n",
      "torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "z = x.view(-1, 5)\n",
    "\n",
    "print(z)\n",
    "print(z.size())\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f275488d-6cce-4a4d-8110-8ad042fa75ff",
   "metadata": {},
   "source": [
    "注意`view()`返回的新`Tensor`与源`Tensor`虽然可能有不同的`size`，但是是共享`data`的，也即更改其中的一个，另外一个也会跟着改变。(顾名思义，view仅仅是改变了对这个张量的观察角度，内部数据并未改变)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bae4cd74-8986-455b-a29c-d8f719ec06e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.5947, 2.5238, 2.4946, 2.2793],\n",
      "        [1.0976, 1.9018, 1.8776, 1.4283],\n",
      "        [1.9780, 1.4874, 1.2762, 1.4631],\n",
      "        [1.8511, 1.0607, 1.4643, 1.8542],\n",
      "        [1.9201, 1.1615, 1.1940, 1.0256]])\n",
      "tensor([2.5947, 2.5238, 2.4946, 2.2793, 1.0976, 1.9018, 1.8776, 1.4283, 1.9780,\n",
      "        1.4874, 1.2762, 1.4631, 1.8511, 1.0607, 1.4643, 1.8542, 1.9201, 1.1615,\n",
      "        1.1940, 1.0256])\n"
     ]
    }
   ],
   "source": [
    "x += 1\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0395ac06-8c9b-4da6-875a-61a232f7af3d",
   "metadata": {},
   "source": [
    "所以如果我们想返回一个真正新的副本（即不共享data内存）该怎么办呢？Pytorch还提供了一个`reshape()`可以改变形状，但是此函数并不能保证返回的是其拷贝，所以不推荐使用。推荐先用`clone`创造一个副本然后再使用`view`。[参考此处](https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0159bed4-8341-4d30-ab4c-8217d8a702a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5947, 1.5238, 1.4946, 1.2793],\n",
      "        [0.0976, 0.9018, 0.8776, 0.4283],\n",
      "        [0.9780, 0.4874, 0.2762, 0.4631],\n",
      "        [0.8511, 0.0607, 0.4643, 0.8542],\n",
      "        [0.9201, 0.1615, 0.1940, 0.0256]])\n",
      "tensor([2.5947, 2.5238, 2.4946, 2.2793, 1.0976, 1.9018, 1.8776, 1.4283, 1.9780,\n",
      "        1.4874, 1.2762, 1.4631, 1.8511, 1.0607, 1.4643, 1.8542, 1.9201, 1.1615,\n",
      "        1.1940, 1.0256])\n"
     ]
    }
   ],
   "source": [
    "x_cp = x.clone().view(20)\n",
    "\n",
    "x -= 1\n",
    "\n",
    "print(x)\n",
    "print(x_cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fecd1d-bbb6-4f62-a3ce-ee537be3731a",
   "metadata": {},
   "source": [
    "另外一个常用的函数就是`item()`, 它可以将一个标量`Tensor`转换成一个Python number："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3ba30d9-f21b-4ec8-bedb-a2bb25383b72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4736])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be527afc-80ae-4500-8ae3-3601ae0e95df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47360336780548096"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# py数字类型\n",
    "x.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182cd027-7a8d-4f44-8dfd-ad932e1839d3",
   "metadata": {},
   "source": [
    "### 线性代数\n",
    "\n",
    "另外，PyTorch还支持一些线性函数，这里提一下，免得用起来的时候自己造轮子，具体用法参考官方文档。如下表所示：\n",
    "PyTorch中的`Tensor`支持超过一百种操作，包括转置、索引、切片、数学运算、线性代数、随机数等等，可参考[官方文档](https://pytorch.org/docs/stable/tensors.html)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be44b53d-6e23-4182-931a-0faf8dbb584d",
   "metadata": {},
   "source": [
    "## 2.2.3 广播机制\n",
    "\n",
    "前面我们看到如何对两个形状相同的`Tensor`做按元素运算。当对两个形状不同的`Tensor`按元素运算时，可能会触发广播（broadcasting）机制：先适当复制元素使这两个`Tensor`形状相同后再按元素运算。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5eada91e-3e8b-4af0-aac9-cfb9aeb283d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1, 3).view(1, 2)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6ffeab5-037b-4d3b-9a22-997ed171efc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.arange(1, 4).view(3, 1)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30037bc6-0007-4223-a17e-3ca34d05dccc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [3, 4],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523f7bc3-1120-4821-bd7b-f32faf5e4583",
   "metadata": {},
   "source": [
    "## 2.2.4 运算的内存开销\n",
    "\n",
    "前面说了，索引操作是不会开辟新内存的，而像`y = x + y`这样的运算是会新开内存的，然后将`y`指向新内存。为了演示这一点，我们可以使用Python自带的`id`函数：如果两个实例的ID一致，那么它们所对应的内存地址相同；反之则不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ec5efc4-48d8-4e51-bc28-5c4acaf163f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 22, 3])\n",
    "\n",
    "y = torch.tensor([41, 32, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e7d5d52-ca6b-43ba-a81d-b6d17008be87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140647201662000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_before = id(y)\n",
    "id_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b99a808-6841-4ea0-a33c-72e0a15b575c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140647207597728\n"
     ]
    }
   ],
   "source": [
    "y = y + x\n",
    "\n",
    "print(id(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99e2c84-d2b7-4cc8-814d-bc5d60810249",
   "metadata": {},
   "source": [
    "如果想指定结果到原来的`y`的内存，我们可以使用前面介绍的索引来进行替换操作。在下面的例子中，我们把`x + y`的结果通过`[:]`写进`y`对应的内存中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fea36e4-1c46-4a56-b204-7ab3a88e1161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140647201665600\n",
      "140647201665600\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([2, 3])\n",
    "print(id(y))\n",
    "\n",
    "y[:] = y + x\n",
    "print(id(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f6b67e-56d0-4d7a-ba12-c2577cbcb149",
   "metadata": {},
   "source": [
    "我们还可以使用运算符全名函数中的`out`参数或者自加运算符`+=`(也即`add_()`)达到上述效果，例如`torch.add(x, y, out=y)`和`y += x`(`y.add_(x)`)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76a6267b-a4ee-4ecf-bc91-f02a13e5ec95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140647201666720\n",
      "140647201666720\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([2, 3])\n",
    "\n",
    "\n",
    "print(id(y))\n",
    "torch.add(x, y, out=y)\n",
    "\n",
    "print(id(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41032a9-44ce-44b1-b127-09ad8197ccb7",
   "metadata": {},
   "source": [
    "## 2.2.5 `Tensor`和NumPy相互转换\n",
    "\n",
    "我们很容易用`numpy()`和`from_numpy()`将`Tensor`和NumPy中的数组相互转换。但是需要注意的一点是：\n",
    "**这两个函数所产生的的`Tensor`和NumPy中的数组共享相同的内存（所以他们之间的转换很快），改变其中一个时另一个也会改变！！！**\n",
    "> 还有一个常用的将NumPy中的array转换成`Tensor`的方法就是`torch.tensor()`, 需要注意的是，此方法总是会进行数据拷贝（就会消耗更多的时间和空间），所以返回的`Tensor`和原来的数据不再共享内存。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d611278d-0dd4-4c5f-a662-f22884e77e6c",
   "metadata": {},
   "source": [
    "### `Tensor`转NumPy\n",
    "\n",
    "使用`numpy()`将`Tensor`转换成NumPy数组:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fee3ec1-4b44-49f5-a58c-c0c5651db067",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = torch.ones(5)  # tensor([1., 1., 1., 1., 1.])\n",
    "\n",
    "b = a.numpy()      # array([1., 1., 1., 1., 1.], dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "646bdd65-bc69-484d-b4ec-7a17feea3eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a += 1  # tensor([2., 2., 2., 2., 2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d50f8254-a65d-4f8d-86a9-41e3732e1cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b += 1  # array([4., 4., 4., 4., 4.], dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cc27c93-244f-498c-b978-56b147cfa8be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3., 3.]) [3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e572a10-4290-47b9-a09d-211ff76697d3",
   "metadata": {},
   "source": [
    "### NumPy数组转`Tensor`\n",
    "\n",
    "使用`from_numpy()`将NumPy数组转换成`Tensor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed260d7b-e7ce-48e7-952f-300f376c95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1a58c29-be9d-4556-9f08-65e02cadf17a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4726d816-8ad3-4ad1-8f92-e7abdcc48e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 3. 3. 3.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a += 1\n",
    "b += 1\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d7a922-6d63-4c60-987a-4c6c2e40f0de",
   "metadata": {},
   "source": [
    "所有在CPU上的`Tensor`（除了`CharTensor`）都支持与NumPy数组相互转换。\n",
    "\n",
    "此外上面提到还有一个常用的方法就是直接用`torch.tensor()`将NumPy数组转换成`Tensor`，需要注意的是该方法总是会进行数据拷贝，返回的`Tensor`和原来的数据不再共享内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c692af4a-36f4-4bc1-aa94-52a6ecb4be14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 4. 4. 4. 4.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "c = torch.tensor(a)\n",
    "\n",
    "a += 1\n",
    "print(a, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6a61f8-25a2-4c17-9381-e224581f2153",
   "metadata": {},
   "source": [
    "## 2.2.6 `Tensor` on GPU\n",
    "\n",
    "用方法`to()`可以将`Tensor`在CPU和GPU（需要硬件支持）之间相互移动。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33bd2623-01a4-4cf0-a8a8-b34f3698ccb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 以下代码只有在PyTorch GPU版本上才会执行\n",
    "if torch.cuda.is_available():\n",
    "    \n",
    "    device = torch.device(\"cuda\")          # GPU\n",
    "    y = torch.ones_like(x, device=device)  # 直接创建一个在GPU上的Tensor\n",
    "    x = x.to(device)                       # 等价于 .to(\"cuda\")\n",
    "    print(\"x: \", x)\n",
    "    z = x + y\n",
    "\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # to()还可以同时更改数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9386355-444c-4fb1-9cb9-2f93a2fc5d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
